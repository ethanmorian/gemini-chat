{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16036efa-cff4-43d6-9044-177bddb959ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaaabab0-360e-408b-b5c9-26cca656d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pytz\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "from torchvision import models, transforms\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61b59d8",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dbd4be2-139a-4089-9ec2-6c64bd457090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathLabelProcessor:\n",
    "    def __init__(self,\n",
    "                 base_path,\n",
    "                 folder_name):\n",
    "        self.base_path = base_path\n",
    "        self.folder_name = folder_name\n",
    "        \n",
    "        self.label_images()\n",
    "        \n",
    "    def find_folders_by_name(self):\n",
    "        matching_folders = []\n",
    "\n",
    "        for root, dirs, files in os.walk(self.base_path):\n",
    "            for dir_name in dirs:\n",
    "                if self.folder_name in dir_name:\n",
    "                    folder_path = os.path.join(root, dir_name)\n",
    "                    matching_folders.append(folder_path)\n",
    "\n",
    "        return matching_folders\n",
    "\n",
    "    def find_image_json_pairs(self, folder_path):\n",
    "        image_paths = []\n",
    "        json_paths = []\n",
    "\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for image_file in filter(lambda x: x.lower().endswith(('jpg', 'png')), files):\n",
    "                image_path = os.path.join(root, image_file)\n",
    "                json_file = f\"{os.path.splitext(image_path)[0]}.json\"\n",
    "                if os.path.isfile(json_file):\n",
    "                    image_paths.append(image_path)\n",
    "                    json_paths.append(json_file)\n",
    "\n",
    "        return image_paths, json_paths\n",
    "\n",
    "    def label_images(self):\n",
    "        self.labeled_image_paths = []\n",
    "\n",
    "        for folder_path in self.find_folders_by_name():\n",
    "            image_paths, json_paths = self.find_image_json_pairs(folder_path)\n",
    "            \n",
    "            for image_path, json_path in zip(image_paths, json_paths):\n",
    "                with open(json_path) as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                label = 1 if data['metaData']['lesions'] == 'A7' else 0\n",
    "                self.labeled_image_paths.append((image_path, label))\n",
    "            \n",
    "        symptomatic_count = sum(1 for _, label in self.labeled_image_paths if label == 0)\n",
    "        asymptomatic_count = sum(1 for _, label in self.labeled_image_paths if label == 1)\n",
    "        \n",
    "        weight_class_0 = 1.0 / symptomatic_count\n",
    "        weight_class_1 = 1.0 / asymptomatic_count\n",
    "        self.class_weights = torch.tensor([weight_class_0, weight_class_1])\n",
    "\n",
    "        print(f'Total cases: {len(self.labeled_image_paths)}')\n",
    "        print(f'Number of symptomatic cases: {symptomatic_count}, Number of asymptomatic cases: {asymptomatic_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89608a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m, in \u001b[0;36mPathLabelProcessor.__init__\u001b[0;34m(self, base_path, folder_name)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_path \u001b[38;5;241m=\u001b[39m base_path\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfolder_name \u001b[38;5;241m=\u001b[39m folder_name\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 43\u001b[0m, in \u001b[0;36mPathLabelProcessor.label_images\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path, json_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(image_paths, json_paths):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(json_path) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 43\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetaData\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlesions\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA7\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabeled_image_paths\u001b[38;5;241m.\u001b[39mappend((image_path, label))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_buffer_decode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, errors, final):\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m    322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_decode(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors, final)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'skin/Train'\n",
    "folder_name = '일반'\n",
    "\n",
    "processor = PathLabelProcessor(base_path=base_path, folder_name=folder_name)\n",
    "\n",
    "data = processor.labeled_image_paths\n",
    "class_weights = processor.class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.data[idx]\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class ImageDataset():\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 transform,\n",
    "                 test_size,\n",
    "                 seed,\n",
    "                 batch_size,\n",
    "                 shuffle,\n",
    "                 num_workers):\n",
    "        dataset = self.make_dataset(data, transform, test_size, seed)\n",
    "        self.dataloader = self.make_dataloader(dataset, batch_size, shuffle, num_workers)\n",
    "        \n",
    "        \n",
    "    def make_dataset(self, data, transform, test_size=None, seed=42):\n",
    "        if test_size:\n",
    "            train_data, val_data = train_test_split(data, \n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=seed)\n",
    "            dataset_dict = {'train': train_data,\n",
    "                            'val': val_data}\n",
    "        else:\n",
    "            dataset_dict = {'test' : data}\n",
    "\n",
    "        dataset = {k: CustomDataset(v, transform[k])\n",
    "                   for k, v in dataset_dict.items()}\n",
    "        \n",
    "        return dataset\n",
    "        \n",
    "    def make_dataloader(self, dataset, batch_size, shuffle, num_workers):\n",
    "        dataloader = {k: DataLoader(dataset=dataset[k],\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=shuffle,\n",
    "                                    num_workers=num_workers,\n",
    "                                    pin_memory=True)\n",
    "                      for k in dataset.keys()}\n",
    "        \n",
    "        for k, v in dataloader.items():\n",
    "            self.print_class_distribution(k, v)\n",
    "        \n",
    "        return dataloader\n",
    "    \n",
    "    def compute_class_counts(self, data_loader):\n",
    "        counts = torch.zeros(2, dtype=torch.long)\n",
    "        \n",
    "        for _, labels in data_loader:\n",
    "            counts += torch.bincount(labels, minlength=2)\n",
    "        \n",
    "        return counts\n",
    "\n",
    "    def print_class_distribution(self, phase, data_loader):\n",
    "        print(f\"Class Distribution for {phase}:\")\n",
    "        class_counts = self.compute_class_counts(data_loader)\n",
    "        for class_label, count in enumerate(class_counts):\n",
    "            print(f\"  Class {class_label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60547f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution for train:\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = {'train': transforms.Compose([transforms.Resize((176, 176)),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomVerticalFlip(),\n",
    "                                          transforms.RandomRotation(degrees=10),\n",
    "                                          transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]),\n",
    "             'val': transforms.Compose([transforms.Resize((232, 232)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])}\n",
    "test_size = 0.2\n",
    "seed = 42\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "dataloader = ImageDataset(data=data,\n",
    "                          transform=transform,\n",
    "                          test_size=test_size,\n",
    "                          seed=seed,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle,\n",
    "                          num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f162d702",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25147140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmUpRestarts(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLossWithLabelSmoothing(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None, smoothing=0.1, num_classes=2, reduction='mean'):\n",
    "        super(FocalLossWithLabelSmoothing, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.smoothing = smoothing\n",
    "        self.num_classes = num_classes\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = targets.to(inputs.device)\n",
    "\n",
    "        target_one_hot = torch.zeros_like(inputs)\n",
    "        target_one_hot.scatter_(1, targets.unsqueeze(1), 1 - self.smoothing)\n",
    "        target_one_hot.scatter_(1, (targets.unsqueeze(1) + 1) % self.num_classes, self.smoothing)\n",
    "\n",
    "        ce_loss = nn.functional.cross_entropy(inputs, target_one_hot, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            self.alpha = self.alpha.to(inputs.device)\n",
    "            focal_loss = self.alpha[targets] * focal_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        elif self.reduction == 'none':\n",
    "            return focal_loss\n",
    "        else:\n",
    "            raise ValueError(\"Invalid reduction option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 device,\n",
    "                 dataloader,\n",
    "                 criterion,\n",
    "                 optimizer,\n",
    "                 scheduler):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        model_name = model.__class__.__name__\n",
    "        self.dataloader = dataloader\n",
    "        self.criterion = criterion.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.best_f1_score = 0.0\n",
    "        korea = pytz.timezone('Asia/Seoul')\n",
    "        now = datetime.now(korea)\n",
    "        start_time = now.strftime('%Y%m%d-%H%M%S')\n",
    "        self.name = f'{start_time}_{model_name}_symptoms.pth'\n",
    "        self.writer = SummaryWriter(log_dir=f'runs/{self.name}')\n",
    "\n",
    "    def calculate_f1_score(self, predicted, labels):\n",
    "        return f1_score(labels, predicted, average='binary')\n",
    "\n",
    "    def calculate_auc_roc(self, predicted, labels):\n",
    "        return roc_auc_score(labels, predicted)\n",
    "\n",
    "    def run_epoch(self, epoch, num_epochs):\n",
    "        for phase in ['train', 'val']:\n",
    "            self.model.train() if phase == 'train' else self.model.eval()\n",
    "            dataloader = self.dataloader[phase]\n",
    "\n",
    "            total_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            all_predicted = []\n",
    "            all_labels = []\n",
    "\n",
    "            for inputs, labels in tqdm(dataloader, desc=f'{phase.capitalize()} Epoch {epoch + 1}/{num_epochs}', unit='batch'):\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = self.model(inputs)\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        self.optimizer.step()\n",
    "                        self.optimizer.zero_grad()\n",
    "\n",
    "                    total_loss += loss.item()\n",
    "\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    all_predicted.extend(predicted.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            avg_loss = total_loss / len(dataloader)\n",
    "            accuracy = correct / total\n",
    "            self.writer.add_scalar(f'Loss/{phase}', avg_loss, epoch)\n",
    "            self.writer.add_scalar(f'Accuracy/{phase}', accuracy, epoch)\n",
    "\n",
    "            if phase == 'val':\n",
    "                current_f1_score = self.calculate_f1_score(np.array(all_predicted), np.array(all_labels))\n",
    "                current_auc_roc = self.calculate_auc_roc(np.array(all_predicted), np.array(all_labels))\n",
    "\n",
    "                self.writer.add_scalar('F1 Score/valid', current_f1_score, epoch)\n",
    "                self.writer.add_scalar('AUC-ROC/valid', current_auc_roc, epoch)\n",
    "\n",
    "                if current_f1_score > self.best_f1_score:\n",
    "                    self.best_f1_score = current_f1_score\n",
    "                    torch.save(self.model, self.name)\n",
    "\n",
    "        lr_value = self.scheduler.get_lr()[0]\n",
    "        self.writer.add_scalar('LearningRate', lr_value, epoch)\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.run_epoch(epoch, num_epochs)\n",
    "\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e89e25-1427-4de0-bf41-fcb94349cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.convnext_large(weights='DEFAULT')\n",
    "for name, param in model.named_parameters():\n",
    "    if \"last_layer\" not in name:\n",
    "        param.requires_grad = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_ftrs = model.classifier[2].in_features\n",
    "model.classifier[2] = nn.Linear(num_ftrs, 2)\n",
    "criterion = FocalLossWithLabelSmoothing(gamma=2, alpha=class_weights, reduction='sum')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0, weight_decay=1e-5)\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=10, T_mult=1, eta_max=0.1,  T_up=10, gamma=0.5)\n",
    "\n",
    "trainer = ModelTrainer(model=model,\n",
    "                       device=device,\n",
    "                       dataloader=dataloader.dataloader,\n",
    "                       criterion=criterion,\n",
    "                       optimizer=optimizer,\n",
    "                       scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397f7da3-9b44-4ecf-8c4a-43dfd0fa71e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1/30: 100%|██████████| 823/823 [01:57<00:00,  7.00batch/s]\n",
      "Val Epoch 1/30: 100%|██████████| 206/206 [00:27<00:00,  7.55batch/s]\n",
      "Train Epoch 2/30: 100%|██████████| 823/823 [01:57<00:00,  7.03batch/s]\n",
      "Val Epoch 2/30: 100%|██████████| 206/206 [00:27<00:00,  7.61batch/s]\n",
      "Train Epoch 3/30: 100%|██████████| 823/823 [01:56<00:00,  7.07batch/s]\n",
      "Val Epoch 3/30: 100%|██████████| 206/206 [00:27<00:00,  7.56batch/s]\n",
      "Train Epoch 4/30: 100%|██████████| 823/823 [02:07<00:00,  6.44batch/s]\n",
      "Val Epoch 4/30: 100%|██████████| 206/206 [00:32<00:00,  6.33batch/s]\n",
      "Train Epoch 5/30: 100%|██████████| 823/823 [03:13<00:00,  4.26batch/s]\n",
      "Val Epoch 5/30: 100%|██████████| 206/206 [00:55<00:00,  3.69batch/s]\n",
      "Train Epoch 6/30: 100%|██████████| 823/823 [03:57<00:00,  3.47batch/s]\n",
      "Val Epoch 6/30: 100%|██████████| 206/206 [00:56<00:00,  3.68batch/s]\n",
      "Train Epoch 7/30: 100%|██████████| 823/823 [03:57<00:00,  3.47batch/s]\n",
      "Val Epoch 7/30: 100%|██████████| 206/206 [00:56<00:00,  3.66batch/s]\n",
      "Train Epoch 8/30: 100%|██████████| 823/823 [03:57<00:00,  3.47batch/s]\n",
      "Val Epoch 8/30: 100%|██████████| 206/206 [00:56<00:00,  3.67batch/s]\n",
      "Train Epoch 9/30: 100%|██████████| 823/823 [03:58<00:00,  3.45batch/s]\n",
      "Val Epoch 9/30: 100%|██████████| 206/206 [00:56<00:00,  3.65batch/s]\n",
      "Train Epoch 10/30: 100%|██████████| 823/823 [03:57<00:00,  3.47batch/s]\n",
      "Val Epoch 10/30: 100%|██████████| 206/206 [00:55<00:00,  3.68batch/s]\n",
      "Train Epoch 11/30: 100%|██████████| 823/823 [03:57<00:00,  3.47batch/s]\n",
      "Val Epoch 11/30: 100%|██████████| 206/206 [00:55<00:00,  3.69batch/s]\n",
      "Train Epoch 12/30: 100%|██████████| 823/823 [03:57<00:00,  3.47batch/s]\n",
      "Val Epoch 12/30: 100%|██████████| 206/206 [00:56<00:00,  3.65batch/s]\n",
      "Train Epoch 13/30: 100%|██████████| 823/823 [03:57<00:00,  3.47batch/s]\n",
      "Val Epoch 13/30: 100%|██████████| 206/206 [00:56<00:00,  3.63batch/s]\n",
      "Train Epoch 14/30: 100%|██████████| 823/823 [03:57<00:00,  3.47batch/s]\n",
      "Val Epoch 14/30: 100%|██████████| 206/206 [00:56<00:00,  3.67batch/s]\n",
      "Train Epoch 15/30: 100%|██████████| 823/823 [03:57<00:00,  3.47batch/s]\n",
      "Val Epoch 15/30: 100%|██████████| 206/206 [00:56<00:00,  3.65batch/s]\n",
      "Train Epoch 16/30: 100%|██████████| 823/823 [03:56<00:00,  3.48batch/s]\n",
      "Val Epoch 16/30: 100%|██████████| 206/206 [00:56<00:00,  3.66batch/s]\n",
      "Train Epoch 17/30: 100%|██████████| 823/823 [03:56<00:00,  3.47batch/s]\n",
      "Val Epoch 17/30: 100%|██████████| 206/206 [00:56<00:00,  3.63batch/s]\n",
      "Train Epoch 18/30: 100%|██████████| 823/823 [03:55<00:00,  3.49batch/s]\n",
      "Val Epoch 18/30: 100%|██████████| 206/206 [00:56<00:00,  3.63batch/s]\n",
      "Train Epoch 19/30: 100%|██████████| 823/823 [03:55<00:00,  3.49batch/s]\n",
      "Val Epoch 19/30: 100%|██████████| 206/206 [00:55<00:00,  3.68batch/s]\n",
      "Train Epoch 20/30: 100%|██████████| 823/823 [03:58<00:00,  3.45batch/s]\n",
      "Val Epoch 20/30: 100%|██████████| 206/206 [00:57<00:00,  3.57batch/s]\n",
      "Train Epoch 21/30: 100%|██████████| 823/823 [03:57<00:00,  3.47batch/s]\n",
      "Val Epoch 21/30: 100%|██████████| 206/206 [00:57<00:00,  3.60batch/s]\n",
      "Train Epoch 22/30: 100%|██████████| 823/823 [03:55<00:00,  3.50batch/s]\n",
      "Val Epoch 22/30: 100%|██████████| 206/206 [00:56<00:00,  3.66batch/s]\n",
      "Train Epoch 23/30: 100%|██████████| 823/823 [03:57<00:00,  3.46batch/s]\n",
      "Val Epoch 23/30: 100%|██████████| 206/206 [00:56<00:00,  3.62batch/s]\n",
      "Train Epoch 24/30: 100%|██████████| 823/823 [03:58<00:00,  3.45batch/s]\n",
      "Val Epoch 24/30: 100%|██████████| 206/206 [00:56<00:00,  3.63batch/s]\n",
      "Train Epoch 25/30: 100%|██████████| 823/823 [03:56<00:00,  3.48batch/s]\n",
      "Val Epoch 25/30: 100%|██████████| 206/206 [00:56<00:00,  3.67batch/s]\n",
      "Train Epoch 26/30: 100%|██████████| 823/823 [03:56<00:00,  3.48batch/s]\n",
      "Val Epoch 26/30: 100%|██████████| 206/206 [00:56<00:00,  3.65batch/s]\n",
      "Train Epoch 27/30: 100%|██████████| 823/823 [03:57<00:00,  3.47batch/s]\n",
      "Val Epoch 27/30: 100%|██████████| 206/206 [00:56<00:00,  3.66batch/s]\n",
      "Train Epoch 28/30: 100%|██████████| 823/823 [03:56<00:00,  3.48batch/s]\n",
      "Val Epoch 28/30: 100%|██████████| 206/206 [00:56<00:00,  3.65batch/s]\n",
      "Train Epoch 29/30: 100%|██████████| 823/823 [03:57<00:00,  3.47batch/s]\n",
      "Val Epoch 29/30: 100%|██████████| 206/206 [00:56<00:00,  3.63batch/s]\n",
      "Train Epoch 30/30: 100%|██████████| 823/823 [03:57<00:00,  3.47batch/s]\n",
      "Val Epoch 30/30: 100%|██████████| 206/206 [00:55<00:00,  3.69batch/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064496eb",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4dac2b9-a8a2-4577-8972-126d23e2a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester:\n",
    "    def __init__(self, path, device, dataloader):\n",
    "        self.device = device\n",
    "        self.dataloader = dataloader\n",
    "        self.load_model(path)\n",
    "        self.evaluate()\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = torch.load(path)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def classify(self):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(self.dataloader):\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                labels.extend(targets.cpu().numpy())\n",
    "                probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "        return predictions, labels, probabilities\n",
    "\n",
    "    def calculate_prob_stats(self, probabilities):\n",
    "        probabilities = np.array(probabilities)\n",
    "        min_probs = np.min(probabilities)\n",
    "        max_probs = np.max(probabilities)\n",
    "        std_probs = np.std(probabilities)\n",
    "        mean_probs = np.mean(probabilities)\n",
    "\n",
    "        return min_probs, max_probs, std_probs, mean_probs\n",
    "\n",
    "    def calculate_percentage(self, value):\n",
    "        return f'{value*100:.2f}%'\n",
    "\n",
    "    def evaluate(self):\n",
    "        predictions, labels, probabilities = self.classify()\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "        min_probs, max_probs, std_probs, mean_probs = self.calculate_prob_stats(probabilities)\n",
    "\n",
    "        print('Evaluation Results:')\n",
    "        print(f'Confusion Matrix:\\n{cm}')\n",
    "        print(f'Accuracy: {self.calculate_percentage(accuracy)}')\n",
    "        print(f'F1 Score: {self.calculate_percentage(f1)}')\n",
    "        print(f'Mean Probability: {self.calculate_percentage(mean_probs)}')\n",
    "        print(f'Max Probability: {self.calculate_percentage(max_probs)}')\n",
    "        print(f'Min Probability: {self.calculate_percentage(min_probs)}')\n",
    "        print(f'Standard Deviation of Probabilities: {std_probs:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62042bbe-8452-4cbb-9cbc-106474e8b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases: 13808\n",
      "Number of symptomatic cases: 138, Number of asymptomatic cases: 13670\n",
      "CPU times: user 844 ms, sys: 316 ms, total: 1.16 s\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'skin/Valid'\n",
    "folder_name = '일반'\n",
    "\n",
    "processor = PathLabelProcessor(base_path=base_path, folder_name=folder_name)\n",
    "\n",
    "data = processor.labeled_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8a9ece9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution for test:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class 0: 138 samples\n",
      "  Class 1: 13670 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432/432 [00:41<00:00, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[  128    10]\n",
      " [ 1931 11739]]\n",
      "Accuracy: 85.94%\n",
      "F1 Score: 91.56%\n",
      "Mean Probability: 50.00%\n",
      "Max Probability: 99.98%\n",
      "Min Probability: 0.02%\n",
      "Standard Deviation of Probabilities: 0.3726\n",
      "CPU times: user 46.1 s, sys: 7.23 s, total: 53.4 s\n",
      "Wall time: 60 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fbb0e4a1d20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "transform = {'test': transforms.Compose([transforms.Resize((232, 232)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])}\n",
    "test_size = None\n",
    "seed = 42\n",
    "batch_size = 32\n",
    "shuffle = False\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "dataloader = ImageDataset(data=data,\n",
    "                          transform=transform,\n",
    "                          test_size=test_size,\n",
    "                          seed=seed,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle,\n",
    "                          num_workers=num_workers)\n",
    "\n",
    "path = '20231215-141835_EfficientNet_개_안검염.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=dataloader.dataloader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45a5a255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution for test:\n",
      "  Class 0: 138 samples\n",
      "  Class 1: 0 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[128  10]\n",
      " [  0   0]]\n",
      "Accuracy: 92.75%\n",
      "F1 Score: 96.24%\n",
      "Mean Probability: 50.00%\n",
      "Max Probability: 91.68%\n",
      "Min Probability: 8.32%\n",
      "Standard Deviation of Probabilities: 0.2129\n",
      "CPU times: user 1.37 s, sys: 1.41 s, total: 2.78 s\n",
      "Wall time: 3.45 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fb9b04b03d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataloader = ImageDataset(data=[item for item in data if item[1] == 0],\n",
    "                          transform=transform,\n",
    "                          test_size=test_size,\n",
    "                          seed=seed,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle,\n",
    "                          num_workers=num_workers)\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=dataloader.dataloader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f3ae528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution for test:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class 0: 0 samples\n",
      "  Class 1: 13670 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 428/428 [00:43<00:00,  9.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[    0     0]\n",
      " [ 1931 11739]]\n",
      "Accuracy: 85.87%\n",
      "F1 Score: 92.40%\n",
      "Mean Probability: 50.00%\n",
      "Max Probability: 99.98%\n",
      "Min Probability: 0.02%\n",
      "Standard Deviation of Probabilities: 0.3739\n",
      "CPU times: user 47.4 s, sys: 7.16 s, total: 54.6 s\n",
      "Wall time: 54.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fbab7225d80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataloader = ImageDataset(data=[item for item in data if item[1] == 1],\n",
    "                          transform=transform,\n",
    "                          test_size=test_size,\n",
    "                          seed=seed,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle,\n",
    "                          num_workers=num_workers)\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=dataloader.dataloader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0ccdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreModelTester:\n",
    "    def __init__(self, path, device, dataloader):\n",
    "        self.device = device\n",
    "        self.dataloader = dataloader\n",
    "        self.model = models.vgg16_bn(pretrained=True)\n",
    "        self.load_model(path)\n",
    "        self.evaluate()\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = models.vgg16_bn(pretrained=True)\n",
    "        nr_filters = self.model.classifier[0].in_features\n",
    "        self.model.classifier = nn.Linear(nr_filters, 1)\n",
    "        state_dict = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "        model_dict = self.model.state_dict()\n",
    "        state_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
    "        model_dict.update(state_dict)\n",
    "        self.model.load_state_dict(model_dict)\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "    def classify(self):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(self.dataloader):\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                labels.extend(targets.cpu().numpy())\n",
    "                probabilities.extend(probs.max(dim=1).values.cpu().numpy())\n",
    "\n",
    "        return predictions, labels, probabilities\n",
    "\n",
    "    def calculate_prob_stats(self, probabilities):\n",
    "        probabilities = np.array(probabilities)\n",
    "        min_probs = np.min(probabilities)\n",
    "        max_probs = np.max(probabilities)\n",
    "        std_probs = np.std(probabilities)\n",
    "        mean_probs = np.mean(probabilities)\n",
    "\n",
    "        return min_probs, max_probs, std_probs, mean_probs\n",
    "\n",
    "    def evaluate(self):\n",
    "        predictions, labels, probabilities = self.classify()\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "        min_probs, max_probs, std_probs, mean_probs = self.calculate_prob_stats(probabilities)\n",
    "\n",
    "        print(\"Evaluation Results:\")\n",
    "        print(f\"Confusion Matrix:\\n{cm}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"Mean Probability: {mean_probs:.4f}\")\n",
    "        print(f\"Max Probability: {max_probs:.4f}\")\n",
    "        print(f\"Min Probability: {min_probs:.4f}\")        \n",
    "        print(f\"Standard Deviation of Probabilities: {std_probs:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b98bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "transform = {'test': transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])}\n",
    "test_size = None\n",
    "seed = 42\n",
    "batch_size = 32\n",
    "shuffle = false\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "dataloader = ImageDataset(data=data,\n",
    "                          transform=transform,\n",
    "                          test_size=test_size,\n",
    "                          seed=seed,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle,\n",
    "                          num_workers=num_workers)\n",
    "\n",
    "path = '숙대모델'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=dataloader.dataloader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataloader = ImageDataset(data=[item for item in data if item[1] == 0],\n",
    "                          transform=transform,\n",
    "                          test_size=test_size,\n",
    "                          seed=seed,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle,\n",
    "                          num_workers=num_workers)\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=dataloader.dataloader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataloader = ImageDataset(data=[item for item in data if item[1] == 1],\n",
    "                          transform=transform,\n",
    "                          test_size=test_size,\n",
    "                          seed=seed,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle,\n",
    "                          num_workers=num_workers)\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=dataloader.dataloader['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
