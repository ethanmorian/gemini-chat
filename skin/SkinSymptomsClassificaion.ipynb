{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4e30ef5-4b40-4e23-b0d8-7cff3e0a2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a523093c-d7ae-49fa-a8dd-31dd287ed3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from collections import Counter\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models, transforms\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d84454e-347f-46b4-83ac-e63b28fb621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathLabelProcessor:\n",
    "    def __init__(self, \n",
    "                 base_path,\n",
    "                 folder_name):\n",
    "        self.base_path = base_path\n",
    "        self.folder_name = folder_name\n",
    "        \n",
    "        self.label_images()\n",
    "      \n",
    "    def find_folders_by_name(self):\n",
    "        matching_folders = []\n",
    "\n",
    "        for root, dirs, files in os.walk(self.base_path):\n",
    "            for dir_name in dirs:\n",
    "                if self.folder_name in dir_name:\n",
    "                    folder_path = os.path.join(root, dir_name)\n",
    "                    matching_folders.append(folder_path)\n",
    "\n",
    "        for folder_path in matching_folders:\n",
    "            print(folder_path)\n",
    "            \n",
    "        return matching_folders\n",
    "\n",
    "    def find_image_json_pairs(self):\n",
    "        image_paths = []\n",
    "        json_paths = []\n",
    "\n",
    "        for folder_path in self.find_folders_by_name():\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for image_file in filter(lambda x: x.lower().endswith(('jpg', 'png')), files):\n",
    "                    image_path = os.path.join(root, image_file)\n",
    "                    json_file = f\"{os.path.splitext(image_path)[0]}.json\"\n",
    "                    if os.path.isfile(json_file):\n",
    "                        image_paths.append(image_path)\n",
    "                        json_paths.append(json_file)\n",
    "\n",
    "        print(f'Total images: {len(image_paths)}, Total JSON files: {len(json_paths)}')\n",
    "        \n",
    "        return image_paths, json_paths\n",
    "\n",
    "    def label_images(self):\n",
    "        self.labeled_image_paths = []\n",
    "\n",
    "        for image_path, json_path in zip(*self.find_image_json_pairs()):\n",
    "            with open(json_path) as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            label = 1 if data['metaData']['lesions'] == 'A7' else 0\n",
    "            self.labeled_image_paths.append((image_path, label))\n",
    "        \n",
    "        self.symptomatic_count = len(Counter(item for item in self.labeled_image_paths if item[1] == 0))\n",
    "        self.asymptomatic_count = len(Counter(item for item in self.labeled_image_paths if item[1] == 1))\n",
    "        \n",
    "        print(f'Total cases: {len(self.labeled_image_paths)}')\n",
    "        print(f'Number of symptomatic cases: {self.symptomatic_count}, Number of asymptomatic cases: {self.asymptomatic_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcbf7d71-5599-4547-9c63-9f27df2ec40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skin/Train/반려견/피부/일반카메라\n",
      "skin/Train/반려묘/피부/일반카메라\n",
      "Total images: 433822, Total JSON files: 433822\n",
      "Total cases: 433822\n",
      "Number of symptomatic cases: 209523, Number of asymptomatic cases: 224299\n",
      "CPU times: user 1min 14s, sys: 35.8 s, total: 1min 50s\n",
      "Wall time: 10min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'skin/Train'\n",
    "folder_name = '일반'\n",
    "\n",
    "processor = PathLabelProcessor(base_path=base_path,\n",
    "                               folder_name=folder_name)\n",
    "\n",
    "labeled_image_paths = processor.labeled_image_paths\n",
    "weight_class_0 = 1.0 / processor.symptomatic_count\n",
    "weight_class_1 = 1.0 / processor.asymptomatic_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42750e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, labeled_image_paths, transform):\n",
    "        self.labeled_image_paths = labeled_image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labeled_image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.labeled_image_paths[idx]\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.65 ms, sys: 931 µs, total: 2.58 ms\n",
      "Wall time: 2.18 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = ImageDataset(labeled_image_paths=labeled_image_paths,\n",
    "                       transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderMaker:\n",
    "    def __init__(self, dataset, batch_size, train_ratio=None, num_workers=None):\n",
    "        self.dataset = dataset\n",
    "        self.train_ratio = train_ratio\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        if train_ratio:\n",
    "            self.split_and_make_dataloader()\n",
    "        else:\n",
    "            self.dataloader = self.make_dataloader(self.dataset)\n",
    "\n",
    "    def make_dataloader(self, dataset, shuffle=False):\n",
    "        dataloader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=shuffle,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        self.inspect_data(dataloader)\n",
    "        \n",
    "        return dataloader\n",
    "\n",
    "    def split_and_make_dataloader(self):\n",
    "        train_size = int(len(self.dataset) * self.train_ratio)\n",
    "        test_size = len(self.dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(self.dataset, [train_size, test_size])\n",
    "\n",
    "        self.train_loader = self.make_dataloader(train_dataset, shuffle=True)\n",
    "        self.test_loader = self.make_dataloader(test_dataset, shuffle=True)\n",
    "\n",
    "    def inspect_data(self, dataloader):\n",
    "        print(\"Inspecting Data...\")\n",
    "\n",
    "        class_counts = {}\n",
    "        for _, labels in dataloader:\n",
    "            for label in labels.tolist():\n",
    "                class_counts[label] = class_counts.get(label, 0) + 1\n",
    "\n",
    "        print(\"- Class Counts:\")\n",
    "        for class_label, count in class_counts.items():\n",
    "            print(f\"  Class {class_label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n",
      "- Class Counts:\n",
      "  Class 1: 179491 samples\n",
      "  Class 0: 167566 samples\n",
      "Inspecting Data...\n",
      "- Class Counts:\n",
      "  Class 0: 41957 samples\n",
      "  Class 1: 44808 samples\n",
      "CPU times: user 1min 19s, sys: 1min 23s, total: 2min 42s\n",
      "Wall time: 23min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 96\n",
    "num_workers = os.cpu_count()\n",
    "train_ratio = 0.8\n",
    "weight_class_0 = 1.0 / processor.symptomatic_count\n",
    "weight_class_1 = 1.0 / processor.asymptomatic_count\n",
    "class_weights = torch.tensor([weight_class_0, weight_class_1])\n",
    "\n",
    "data_loader = DataLoaderMaker(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    train_ratio=train_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 device,\n",
    "                 train_dataloader,\n",
    "                 valid_dataloader,\n",
    "                 loss_fn,\n",
    "                 optimizer,\n",
    "                 scheduler,\n",
    "                 pet_type,\n",
    "                 lesion):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.loss_fn = loss_fn.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.best_f1_score = 0.0\n",
    "        korea = pytz.timezone('Asia/Seoul')\n",
    "        now = datetime.now(korea)\n",
    "        start_time = now.strftime('%Y%m%d-%H%M%S')\n",
    "        self.name = f'{start_time}_{pet_type}_{lesion}.pth'\n",
    "        self.writer = SummaryWriter(log_dir=f'runs/{self.name}')\n",
    "\n",
    "    def calculate_f1_score(self, predicted, labels):\n",
    "        return f1_score(\n",
    "            labels,\n",
    "            predicted,\n",
    "            average='binary'\n",
    "        )\n",
    "\n",
    "    def calculate_auc_roc(self, predicted, labels):\n",
    "        return roc_auc_score(\n",
    "            labels,\n",
    "            predicted\n",
    "        )\n",
    "\n",
    "    def train_one_epoch(self, epoch, num_epochs):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    \n",
    "        for step, (inputs, labels) in enumerate(tqdm(self.train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "    \n",
    "            outputs = self.model(inputs)\n",
    "            \n",
    "            loss = self.loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "            loss.backward()\n",
    "    \n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "    \n",
    "        self.scheduler.step()\n",
    "        self.writer.add_scalar(\n",
    "            'LearningRate',\n",
    "            self.scheduler.get_last_lr()[0],\n",
    "            epoch\n",
    "        )\n",
    "    \n",
    "        avg_loss = total_loss / len(self.train_dataloader)\n",
    "        accuracy = correct / total\n",
    "        self.writer.add_scalar('Loss/train', avg_loss, epoch)        \n",
    "        self.writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
    "\n",
    "    def eval_one_epoch(self, epoch):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_predicted = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.valid_dataloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "        \n",
    "                outputs = self.model(inputs)\n",
    "        \n",
    "                loss = self.loss_fn(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "        \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "                all_predicted.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(self.valid_dataloader)\n",
    "        accuracy = correct / total\n",
    "        self.writer.add_scalar('Loss/valid', avg_loss, epoch)\n",
    "        self.writer.add_scalar('Accuracy/valid', accuracy, epoch)\n",
    "        \n",
    "        current_f1_score = self.calculate_f1_score(\n",
    "            np.array(all_predicted),\n",
    "            np.array(all_labels)\n",
    "        )\n",
    "        current_auc_roc = self.calculate_auc_roc(\n",
    "            np.array(all_predicted),\n",
    "            np.array(all_labels)\n",
    "        )\n",
    "        \n",
    "        self.writer.add_scalar('F1 Score/valid', current_f1_score, epoch)\n",
    "        self.writer.add_scalar('AUC-ROC/valid', current_auc_roc, epoch)\n",
    "        \n",
    "        if current_f1_score > self.best_f1_score:\n",
    "            self.best_f1_score = current_f1_score\n",
    "            torch.save(self.model, self.name)\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train_one_epoch(epoch, num_epochs)\n",
    "            self.eval_one_epoch(epoch)\n",
    "            \n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d862ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b1()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "num_classes = 2\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "trainer = ModelTrainer(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    train_dataloader=data_loader.train_loader,\n",
    "    valid_dataloader=data_loader.test_loader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43828f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 3616/3616 [30:51<00:00,  1.95batch/s]\n",
      "Epoch 2/30: 100%|██████████| 3616/3616 [30:48<00:00,  1.96batch/s]\n",
      "Epoch 3/30: 100%|██████████| 3616/3616 [30:48<00:00,  1.96batch/s]\n",
      "Epoch 4/30: 100%|██████████| 3616/3616 [30:49<00:00,  1.96batch/s]\n",
      "Epoch 5/30: 100%|██████████| 3616/3616 [30:49<00:00,  1.96batch/s]\n",
      "Epoch 6/30: 100%|██████████| 3616/3616 [30:48<00:00,  1.96batch/s]\n",
      "Epoch 7/30: 100%|██████████| 3616/3616 [30:48<00:00,  1.96batch/s]\n",
      "Epoch 8/30: 100%|██████████| 3616/3616 [30:48<00:00,  1.96batch/s]\n",
      "Epoch 9/30: 100%|██████████| 3616/3616 [30:49<00:00,  1.96batch/s]\n",
      "Epoch 10/30: 100%|██████████| 3616/3616 [30:49<00:00,  1.96batch/s]\n",
      "Epoch 11/30: 100%|██████████| 3616/3616 [30:49<00:00,  1.95batch/s]\n",
      "Epoch 12/30: 100%|██████████| 3616/3616 [30:50<00:00,  1.95batch/s]\n",
      "Epoch 13/30: 100%|██████████| 3616/3616 [30:49<00:00,  1.95batch/s]\n",
      "Epoch 14/30: 100%|██████████| 3616/3616 [30:49<00:00,  1.95batch/s]\n",
      "Epoch 15/30: 100%|██████████| 3616/3616 [30:50<00:00,  1.95batch/s]\n",
      "Epoch 16/30: 100%|██████████| 3616/3616 [30:49<00:00,  1.95batch/s]\n",
      "Epoch 17/30: 100%|██████████| 3616/3616 [30:49<00:00,  1.95batch/s]\n",
      "Epoch 18/30: 100%|██████████| 3616/3616 [30:49<00:00,  1.95batch/s]\n",
      "Epoch 19/30: 100%|██████████| 3616/3616 [30:49<00:00,  1.95batch/s]\n",
      "Epoch 20/30: 100%|██████████| 3616/3616 [30:50<00:00,  1.95batch/s]\n",
      "Epoch 21/30: 100%|██████████| 3616/3616 [30:50<00:00,  1.95batch/s]\n",
      "Epoch 22/30: 100%|██████████| 3616/3616 [30:50<00:00,  1.95batch/s]\n",
      "Epoch 23/30: 100%|██████████| 3616/3616 [30:49<00:00,  1.95batch/s]\n",
      "Epoch 24/30:  33%|███▎      | 1181/3616 [10:08<20:34,  1.97batch/s]"
     ]
    }
   ],
   "source": [
    "trainer.train(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d89ab05-4279-403f-b731-23f1f3357d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester:\n",
    "    def __init__(self, path, device, dataloader):\n",
    "        self.device = device\n",
    "        self.dataloader = dataloader\n",
    "        self.load_model(path)\n",
    "        self.evaluate()\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = torch.load(path)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def classify(self):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(self.dataloader):\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                labels.extend(targets.cpu().numpy())\n",
    "                probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "        return predictions, labels, probabilities\n",
    "\n",
    "    def calculate_prob_stats(self, probabilities):\n",
    "        probabilities = np.array(probabilities)\n",
    "        min_probs = np.min(probabilities)\n",
    "        max_probs = np.max(probabilities)\n",
    "        std_probs = np.std(probabilities)\n",
    "        mean_probs = np.mean(probabilities)\n",
    "\n",
    "        return min_probs, max_probs, std_probs, mean_probs\n",
    "\n",
    "    def calculate_percentage(self, value):\n",
    "        return f'{value*100:.2f}%'\n",
    "\n",
    "    def evaluate(self):\n",
    "        predictions, labels, probabilities = self.classify()\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "        min_probs, max_probs, std_probs, mean_probs = self.calculate_prob_stats(probabilities)\n",
    "\n",
    "        print('Evaluation Results:')\n",
    "        print(f'Confusion Matrix:\\n{cm}')\n",
    "        print(f'Accuracy: {self.calculate_percentage(accuracy)}')\n",
    "        print(f'F1 Score: {self.calculate_percentage(f1)}')\n",
    "        print(f'Mean Probability: {self.calculate_percentage(mean_probs)}')\n",
    "        print(f'Max Probability: {self.calculate_percentage(max_probs)}')\n",
    "        print(f'Min Probability: {self.calculate_percentage(min_probs)}')\n",
    "        print(f'Standard Deviation of Probabilities: {std_probs:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skin/Valid/반려견/피부/일반카메라\n",
      "skin/Valid/반려묘/피부/일반카메라\n",
      "Total images: 54223, Total JSON files: 54223\n",
      "Total cases: 54223\n",
      "Number of symptomatic cases: 26189, Number of asymptomatic cases: 28034\n",
      "CPU times: user 10.1 s, sys: 4.97 s, total: 15.1 s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'skin/Valid'\n",
    "folder_name = '일반'\n",
    "\n",
    "processor = PathLabelProcessor(base_path=base_path, folder_name=folder_name)\n",
    "\n",
    "labeled_image_paths = processor.labeled_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Class Counts:\n",
      "  Class 0: 26189 samples\n",
      "  Class 1: 28034 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1695/1695 [02:43<00:00, 10.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[21207  4982]\n",
      " [ 7644 20390]]\n",
      "Accuracy: 76.71%\n",
      "F1 Score: 76.70%\n",
      "Mean Probability: 50.00%\n",
      "Max Probability: 100.00%\n",
      "Min Probability: 0.00%\n",
      "Standard Deviation of Probabilities: 0.3096\n",
      "CPU times: user 1min 27s, sys: 20.5 s, total: 1min 48s\n",
      "Wall time: 5min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fe3283cd720>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([transforms.Resize((240, 240))])\n",
    "\n",
    "dataset = ImageDataset(\n",
    "    labeled_image_paths=labeled_image_paths,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "data_loader = DataLoaderMaker(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "path = '20231207-111838_symptoms.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n",
      "- Class Counts:\n",
      "  Class 0: 26189 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 819/819 [01:18<00:00, 10.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[21207  4982]\n",
      " [    0     0]]\n",
      "Accuracy: 80.98%\n",
      "F1 Score: 89.49%\n",
      "Mean Probability: 50.00%\n",
      "Max Probability: 99.93%\n",
      "Min Probability: 0.07%\n",
      "Standard Deviation of Probabilities: 0.2832\n",
      "CPU times: user 41.3 s, sys: 10.8 s, total: 52.1 s\n",
      "Wall time: 2min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fe329c034f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(\n",
    "    labeled_image_paths=[item for item in labeled_image_paths if item[1] == 0],\n",
    "    transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb9c16c-eed2-4f98-917f-d76f634d5d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n",
      "- Class Counts:\n",
      "  Class 1: 28034 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 877/877 [01:25<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[    0     0]\n",
      " [ 7644 20390]]\n",
      "Accuracy: 72.73%\n",
      "F1 Score: 84.21%\n",
      "Mean Probability: 50.00%\n",
      "Max Probability: 100.00%\n",
      "Min Probability: 0.00%\n",
      "Standard Deviation of Probabilities: 0.3324\n",
      "CPU times: user 44.9 s, sys: 11.3 s, total: 56.2 s\n",
      "Wall time: 2min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fe3283cfca0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(\n",
    "    labeled_image_paths=[item for item in labeled_image_paths if item[1] == 1],\n",
    "    transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreModelTester:\n",
    "    def __init__(self, path, device, dataloader):\n",
    "        self.device = device\n",
    "        self.dataloader = dataloader\n",
    "        self.model = models.vgg16_bn(pretrained=True)\n",
    "        self.load_model(path)\n",
    "        self.evaluate()\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = models.vgg16_bn(pretrained=True)\n",
    "        nr_filters = self.model.classifier[0].in_features\n",
    "        self.model.classifier = nn.Linear(nr_filters, 1)\n",
    "        state_dict = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "        model_dict = self.model.state_dict()\n",
    "        state_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
    "        model_dict.update(state_dict)\n",
    "        self.model.load_state_dict(model_dict)\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "    def classify(self):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(self.dataloader):\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                labels.extend(targets.cpu().numpy())\n",
    "                probabilities.extend(probs.max(dim=1).values.cpu().numpy())\n",
    "\n",
    "        return predictions, labels, probabilities\n",
    "\n",
    "    def calculate_prob_stats(self, probabilities):\n",
    "        probabilities = np.array(probabilities)\n",
    "        min_probs = np.min(probabilities)\n",
    "        max_probs = np.max(probabilities)\n",
    "        std_probs = np.std(probabilities)\n",
    "        mean_probs = np.mean(probabilities)\n",
    "\n",
    "        return min_probs, max_probs, std_probs, mean_probs\n",
    "\n",
    "    def evaluate(self):\n",
    "        predictions, labels, probabilities = self.classify()\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "        min_probs, max_probs, std_probs, mean_probs = self.calculate_prob_stats(probabilities)\n",
    "\n",
    "        print(\"Evaluation Results:\")\n",
    "        print(f\"Confusion Matrix:\\n{cm}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"Mean Probability: {mean_probs:.4f}\")\n",
    "        print(f\"Max Probability: {max_probs:.4f}\")\n",
    "        print(f\"Min Probability: {min_probs:.4f}\")        \n",
    "        print(f\"Standard Deviation of Probabilities: {std_probs:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(\n",
    "    labeled_image_paths=labeled_image_paths,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "data_loader = DataLoaderMaker(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "path = 'pre_eye.pt'\n",
    "\n",
    "PreModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(\n",
    "    labeled_image_paths=labeled_image_paths,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "data_loader = DataLoaderMaker(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "PreModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(\n",
    "    labeled_image_paths=labeled_image_paths,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "data_loader = DataLoaderMaker(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers)\n",
    "\n",
    "PreModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
