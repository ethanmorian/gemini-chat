{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e30ef5-4b40-4e23-b0d8-7cff3e0a2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a523093c-d7ae-49fa-a8dd-31dd287ed3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models, transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d84454e-347f-46b4-83ac-e63b28fb621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathLabelProcessor:\n",
    "    def __init__(self, \n",
    "                 base_path,\n",
    "                 folder_name,\n",
    "                 devices,\n",
    "                 symptom):\n",
    "        self.base_path = base_path\n",
    "        self.folder_name = folder_name\n",
    "        self.devices = devices\n",
    "        self.symptom = symptom\n",
    "        \n",
    "        self.label_images()\n",
    "      \n",
    "    def find_folders_by_name(self):\n",
    "        matching_folders = []\n",
    "\n",
    "        for root, dirs, files in os.walk(self.base_path):\n",
    "            for dir_name in dirs:\n",
    "                if self.folder_name in dir_name:\n",
    "                    folder_path = os.path.join(root, dir_name)\n",
    "                    matching_folders.append(folder_path)\n",
    "\n",
    "        for folder_path in matching_folders:\n",
    "            print(folder_path)\n",
    "            \n",
    "        return matching_folders\n",
    "\n",
    "    def find_image_json_pairs(self):\n",
    "        image_paths = []\n",
    "        json_paths = []\n",
    "\n",
    "        for folder_path in self.find_folders_by_name():\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for image_file in filter(lambda x: x.lower().endswith(('jpg', 'png')), files):\n",
    "                    image_path = os.path.join(root, image_file)\n",
    "                    json_file = f\"{os.path.splitext(image_path)[0]}.json\"\n",
    "                    if os.path.isfile(json_file):\n",
    "                        image_paths.append(image_path)\n",
    "                        json_paths.append(json_file)\n",
    "\n",
    "        print(f'Total images: {len(image_paths)}, Total JSON files: {len(json_paths)}')\n",
    "        \n",
    "        return image_paths, json_paths\n",
    "\n",
    "    def label_images(self):\n",
    "        self.labeled_image_paths = []\n",
    "\n",
    "        for image_path, json_path in zip(*self.find_image_json_pairs()):\n",
    "            with open(json_path) as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            label = 0 if data['metaData']['lesions'] == 'A7' else 1\n",
    "            self.labeled_image_paths.append((image_path, label))\n",
    "        \n",
    "        self.symptomatic_count = len(Counter(item for item in self.labeled_image_paths if item[1] == 0))\n",
    "        self.asymptomatic_count = len(Counter(item for item in self.labeled_image_paths if item[1] == 1))\n",
    "\n",
    "        print(f'Total cases: {len(self.labeled_image_paths)}')\n",
    "        print(f'Number of symptomatic cases: {self.symptomatic_count}, Number of asymptomatic cases: {self.asymptomatic_count}')\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, labeled_image_paths, transform):\n",
    "        self.labeled_image_paths = labeled_image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labeled_image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.labeled_image_paths[idx]\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "        label = torch.tensor([label], dtype=torch.float32)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class DataLoaderMaker:\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 batch_size,\n",
    "                 train_ratio=0,\n",
    "                 num_workers=None):\n",
    "        self.dataset = dataset\n",
    "        self.train_ratio = train_ratio\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        if train_ratio:\n",
    "            self.split_and_make_dataloader()\n",
    "        else:\n",
    "            self.dataloader = self.make_dataloader(self.dataset)\n",
    "\n",
    "    def make_dataloader(self, dataset, shuffle=False):\n",
    "        dataloader = DataLoader(dataset=dataset,\n",
    "                                batch_size=self.batch_size,\n",
    "                                shuffle=shuffle,\n",
    "                                num_workers=self.num_workers,\n",
    "                                pin_memory=True)\n",
    "        \n",
    "        self.inspect_data(dataloader)\n",
    "        \n",
    "        return dataloader\n",
    "\n",
    "    def split_and_make_dataloader(self):\n",
    "        train_size = int(len(self.dataset) * self.train_ratio)\n",
    "        test_size = len(self.dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(self.dataset, [train_size, test_size])\n",
    "\n",
    "        self.train_loader = self.make_dataloader(train_dataset, shuffle=True)\n",
    "        self.test_loader = self.make_dataloader(test_dataset, shuffle=True)\n",
    "\n",
    "    def inspect_data(self, dataloader):\n",
    "        print(\"Inspecting Data...\")\n",
    "\n",
    "        class_counts = {}\n",
    "        for _, labels in dataloader:\n",
    "            labels = labels.type(torch.int)\n",
    "            for label in labels.tolist():\n",
    "                label_tuple = tuple(label)\n",
    "                class_counts[label_tuple] = class_counts.get(label_tuple, 0) + 1\n",
    "\n",
    "        print(\"- Class Counts:\")\n",
    "        for class_label, count in class_counts.items():\n",
    "            print(f\"  Class {class_label}: {count} samples\")\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 device,\n",
    "                 train_dataloader,\n",
    "                 valid_dataloader,\n",
    "                 loss_fn,\n",
    "                 optimizer,\n",
    "                 scheduler):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.best_f1_score = 0.0\n",
    "        self.start_time = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "        self.writer = SummaryWriter(log_dir=f'runs/{self.start_time}')\n",
    "\n",
    "    def calculate_f1_score(self, predicted, labels):\n",
    "        return f1_score(labels, predicted, average='binary')\n",
    "\n",
    "    def calculate_auc_roc(self, predicted, labels):\n",
    "        return roc_auc_score(labels, predicted)\n",
    "\n",
    "    def train_one_epoch(self, epoch, num_epochs):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    \n",
    "        for step, (inputs, labels) in enumerate(tqdm(self.train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "    \n",
    "            outputs = self.model(inputs)\n",
    "    \n",
    "            loss = self.loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predicted = (probs > 0.5).int()\n",
    "    \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "            loss.backward()\n",
    "    \n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "    \n",
    "        self.scheduler.step()\n",
    "        self.writer.add_scalar('LearningRate', self.scheduler.get_last_lr()[0], epoch)\n",
    "    \n",
    "        avg_loss = total_loss / len(self.train_dataloader)\n",
    "        accuracy = correct / total\n",
    "        self.writer.add_scalar('Loss/train', avg_loss, epoch)        \n",
    "        self.writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
    "\n",
    "    def eval_one_epoch(self, epoch):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_predicted = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.valid_dataloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "        \n",
    "                outputs = self.model(inputs)\n",
    "        \n",
    "                loss = self.loss_fn(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "        \n",
    "                probs = torch.sigmoid(outputs)\n",
    "                predicted = (probs > 0.5).int()\n",
    "        \n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "                all_predicted.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(self.valid_dataloader)\n",
    "        accuracy = correct / total\n",
    "        self.writer.add_scalar('Loss/valid', avg_loss, epoch)\n",
    "        self.writer.add_scalar('Accuracy/valid', accuracy, epoch)\n",
    "        \n",
    "        current_f1_score = self.calculate_f1_score(np.array(all_predicted), np.array(all_labels))\n",
    "        current_auc_roc = self.calculate_auc_roc(np.array(all_predicted), np.array(all_labels))\n",
    "        \n",
    "        self.writer.add_scalar('F1 Score/valid', current_f1_score, epoch)\n",
    "        self.writer.add_scalar('AUC-ROC/valid', current_auc_roc, epoch)\n",
    "        \n",
    "        if current_f1_score > self.best_f1_score:\n",
    "            self.best_f1_score = current_f1_score\n",
    "            torch.save(self.model, f'{self.start_time}.pth')\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train_one_epoch(epoch, num_epochs)\n",
    "            self.eval_one_epoch(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcbf7d71-5599-4547-9c63-9f27df2ec40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 610329\n",
      "Inspecting Data...\n",
      "- Images shape: torch.Size([64, 3, 240, 240]), Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1])\n",
      "Inspecting Data...\n",
      "- Images shape: torch.Size([64, 3, 240, 240]), Labels: tensor([0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'skin/Camera/Train'\n",
    "folder_name = '일반'\n",
    "devices = ['스마트폰', '일반카메라']\n",
    "symptom = ['유', '상', '하', '초기', '비성숙', '성숙']\n",
    "\n",
    "processor  = PathLabelProcessor(base_path=base_path,\n",
    "                                folder_name=folder_name,\n",
    "                                pet_type=pet_type,\n",
    "                                devices=devices,\n",
    "                                symptom=symptom)\n",
    "\n",
    "labeled_image_paths = processor.labeled_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = ImageDataset(labeled_image_paths=labeled_image_paths,\n",
    "                       transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size = 96\n",
    "num_workers = os.cpu_count()\n",
    "train_ratio = 0.8\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              train_ratio=train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d862ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b1()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, 1)\n",
    "pos_weight = torch.tensor([processor.symptomatic_count / processor.asymptomatic_count], device=device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.01)\n",
    "\n",
    "trainer = ModelTrainer(model=model,\n",
    "                       device=device,\n",
    "                       train_dataloader=data_loader.train_loader,\n",
    "                       valid_dataloader=data_loader.test_loader,\n",
    "                       loss_fn=loss_fn,\n",
    "                       optimizer=optimizer,\n",
    "                       scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43828f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/96:  28%|██▊       | 2397/8583 [14:34<36:27,  2.83batch/s]"
     ]
    }
   ],
   "source": [
    "trainer.train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skin/Valid/반려견/피부/일반카메라\n",
      "skin/Valid/반려묘/피부/일반카메라\n",
      "Total images: 54223, Total JSON files: 54223\n",
      "Total cases: 54223\n",
      "Number of symptomatic cases: 28034, Number of asymptomatic cases: 26189\n",
      "CPU times: user 2.3 s, sys: 631 ms, total: 2.93 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'skin/Valid'\n",
    "folder_name = '일반'\n",
    "devices = ['스마트폰', '일반카메라']\n",
    "symptom = ['유', '상', '하', '초기', '비성숙', '성숙']\n",
    "\n",
    "processor  = PathLabelProcessor(base_path=base_path,\n",
    "                                folder_name=folder_name,\n",
    "                                devices=devices,\n",
    "                                symptom=symptom)\n",
    "\n",
    "labeled_image_paths = processor.labeled_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 701 µs, sys: 0 ns, total: 701 µs\n",
      "Wall time: 717 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = ImageDataset(labeled_image_paths=labeled_image_paths,\n",
    "                       transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Class Counts:\n",
      "  Class (1,): 26189 samples\n",
      "  Class (0,): 28034 samples\n",
      "CPU times: user 10.6 s, sys: 10 s, total: 20.7 s\n",
      "Wall time: 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 32\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d89ab05-4279-403f-b731-23f1f3357d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester:\n",
    "    def __init__(self, path, device, dataloader):\n",
    "        self.device = device\n",
    "        self.dataloader = dataloader\n",
    "        self.load_model(path)\n",
    "        self.evaluate()\n",
    "\n",
    "    def load_model(self, path):\n",
    "        loaded_model = torch.load(path)\n",
    "        self.model.load_state_dict(loaded_model.state_dict())\n",
    "        self.model.to(self.device)\n",
    "        print(\"Loaded Model Information:\")\n",
    "        print(self.model)\n",
    "\n",
    "    def classify(self):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(self.dataloader):\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                labels.extend(targets.cpu().numpy())\n",
    "                probabilities.extend(probs.max(dim=1).values.cpu().numpy())\n",
    "\n",
    "        return predictions, labels, probabilities\n",
    "\n",
    "    def calculate_prob_stats(self, probabilities):\n",
    "        probabilities = np.array(probabilities)\n",
    "        min_probs = np.min(probabilities)\n",
    "        max_probs = np.max(probabilities)\n",
    "        std_probs = np.std(probabilities)\n",
    "        mean_probs = np.mean(probabilities)\n",
    "\n",
    "        return min_probs, max_probs, std_probs, mean_probs\n",
    "\n",
    "    def evaluate(self):\n",
    "        predictions, labels, probabilities = self.classify()\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        precision = precision_score(labels, predictions)\n",
    "        recall = recall_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions)\n",
    "\n",
    "        min_probs, max_probs, std_probs, mean_probs = self.calculate_prob_stats(probabilities)\n",
    "\n",
    "        print(\"Evaluation Results:\")\n",
    "        print(f\"Confusion Matrix:\\n{cm}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"Min Probability: {min_probs:.4f}\")\n",
    "        print(f\"Max Probability: {max_probs:.4f}\")\n",
    "        print(f\"Standard Deviation of Probabilities: {std_probs:.4f}\")\n",
    "        print(f\"Mean Probability: {mean_probs:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bb9c16c-eed2-4f98-917f-d76f634d5d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1695/1695 [02:47<00:00, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[24957  3077]\n",
      " [12881 13308]]\n",
      "Accuracy: 0.7057\n",
      "Precision: 0.8122\n",
      "Recall: 0.5082\n",
      "F1 Score: 0.6252\n",
      "Min Probability: 0.5000\n",
      "Max Probability: 0.9994\n",
      "Standard Deviation of Probabilities: 0.1499\n",
      "Mean Probability: 0.7343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7f4e2d0fbee0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'best_model.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1695/1695 [02:45<00:00, 10.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[ 9572 18462]\n",
      " [ 7232 18957]]\n",
      "Accuracy: 0.5261\n",
      "Precision: 0.5066\n",
      "Recall: 0.7239\n",
      "F1 Score: 0.5961\n",
      "Min Probability: 0.5000\n",
      "Max Probability: 1.0000\n",
      "Standard Deviation of Probabilities: 0.1440\n",
      "Mean Probability: 0.8749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7f4e2cf50730>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'best_model1.pth'\n",
    "model = models.efficientnet_b1()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 2\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "ModelTester(path=path, model=model, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1695/1695 [02:46<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[12989 15045]\n",
      " [13021 13168]]\n",
      "Accuracy: 0.4824\n",
      "Precision: 0.4667\n",
      "Recall: 0.5028\n",
      "F1 Score: 0.4841\n",
      "Min Probability: 0.5000\n",
      "Max Probability: 1.0000\n",
      "Standard Deviation of Probabilities: 0.1503\n",
      "Mean Probability: 0.8254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7f4e2d17e620>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'best_model2.pth'\n",
    "model = models.efficientnet_b1()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 2\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "ModelTester(path=path, model=model, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4c4c86-f3df-4be9-96da-519a1ab5210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier:\n",
    "    def __init__(self, device, image_path, image_transform, model_weights_path, model):\n",
    "        self.image_path = image_path\n",
    "        self.image_transform = image_transform\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        self.load_model_weights(model_weights_path)\n",
    "\n",
    "    def preprocess_image(self):\n",
    "        image = Image.open(self.image_path)\n",
    "        input_data = self.image_transform(image).unsqueeze(0)\n",
    "        input_data = input_data.to(self.device)\n",
    "        return input_data\n",
    "\n",
    "    def load_model_weights(self, weights_path):\n",
    "        weights = torch.load(weights_path)\n",
    "        self.model.load_state_dict(weights)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def classify_image(self):\n",
    "        self.model.eval()\n",
    "        input_data = self.preprocess_image()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_data)\n",
    "        \n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "        predicted_prob, predicted_class = torch.max(probabilities, 1)\n",
    "        \n",
    "        class_label = \"Disease\" if predicted_class.item() == 0 else \"Normal\"\n",
    "        class_prob = probabilities[0, predicted_class].item() * 100\n",
    "\n",
    "        print(f\"The image is predicted to be {class_label} with {class_prob:.2f}% probability.\")\n",
    "                \n",
    "        return predicted_class.item(), class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b4ad0-2f24-4da5-a70d-cf700fc9188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "image_path = 'kIHjZsKQ6HdQ.jpg'\n",
    "image_transform = transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "model_weights_path = 'best_model.pth'\n",
    "model = models.efficientnet_b1()\n",
    "num_classes = 2\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "classifier = ImageClassifier(device=device,\n",
    "                             image_path=image_path,\n",
    "                             image_transform=image_transform,\n",
    "                             model_weights_path=model_weights_path,\n",
    "                             model=model)\n",
    "\n",
    "predicted_class = classifier.classify_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7b618-1b79-446a-82d3-afef7c96575b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
