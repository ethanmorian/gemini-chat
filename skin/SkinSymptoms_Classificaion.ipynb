{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e30ef5-4b40-4e23-b0d8-7cff3e0a2c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a523093c-d7ae-49fa-a8dd-31dd287ed3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import json\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d84454e-347f-46b4-83ac-e63b28fb621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, path, transform, crop=False):\n",
    "        self.image_files = []\n",
    "        self.box_locations = [] if crop else None\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "        self.crop = crop\n",
    "\n",
    "        for root, dirs, files in os.walk(path): \n",
    "            for dir in dirs:\n",
    "                dir_path = os.path.join(root, dir)\n",
    "                files = glob.glob(os.path.join(dir_path, '*'))\n",
    "                files.sort()  \n",
    "\n",
    "                for file in files:\n",
    "                    if file.endswith('.jpg'):\n",
    "                        json_file = file.replace('.jpg', '.json')\n",
    "\n",
    "                        if json_file in files:\n",
    "                            try:\n",
    "                                with open(json_file, 'r') as f:\n",
    "                                    json_content = json.load(f)\n",
    "                                    label = 0 if json_content['metaData']['lesions'] == 'A7' else 1\n",
    "                                    box = []\n",
    "                                    for info in json_content['labelingInfo']:\n",
    "                                        if 'box' in info:\n",
    "                                            box.extend(info['box']['location'])\n",
    "\n",
    "                                    self.image_files.append(file)\n",
    "                                    self.labels.append(label)\n",
    "                                    \n",
    "                                    if self.crop:\n",
    "                                        box = json_content['label']['label_bbox']\n",
    "                                        self.box_locations.append(box)\n",
    "                            except Exception as e:\n",
    "                                print(f'Error processing file {json_file}: {e}')\n",
    "\n",
    "    def calculate_crop_size(self, box_locations):\n",
    "        x_coords = [box['x'] for box in box_locations]\n",
    "        y_coords = [box['y'] for box in box_locations]\n",
    "        widths = [box['width'] for box in box_locations]\n",
    "        heights = [box['height'] for box in box_locations]\n",
    "\n",
    "        min_x = min(x_coords)\n",
    "        min_y = min(y_coords)\n",
    "        max_x = max(x + width for x, width in zip(x_coords, widths))\n",
    "        max_y = max(y + height for y, height in zip(y_coords, heights))\n",
    "\n",
    "        return (min_x, min_y, max_x, max_y)\n",
    "\n",
    "    def crop_image(self, image_path, box_locations):\n",
    "        crop_size = self.calculate_crop_size(box_locations)\n",
    "        image = Image.open(image_path).crop(crop_size)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_files[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.crop:\n",
    "            box_locations = self.box_locations[idx]\n",
    "            image = self.crop_image(image_path, box_locations) if box_locations else Image.open(image_path)\n",
    "        else:\n",
    "            image = Image.open(image_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class DataLoaderMaker:\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 train_ratio,\n",
    "                 batch_size,\n",
    "                 num_workers):\n",
    "        self.dataset = dataset\n",
    "        self.train_ratio = train_ratio\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        print(f\"Total dataset size: {len(self.dataset)}\")\n",
    "        print(f\"Total positive size: {dataset.labels.count(0)}\")\n",
    "        print(f\"Total negative size: {dataset.labels.count(1)}\")\n",
    "\n",
    "        if 1 > train_ratio > 0:\n",
    "            self.split_and_make_dataloader(train_ratio)\n",
    "            self.inspect_data(self.train_loader)\n",
    "            self.inspect_data(self.test_loader)\n",
    "        else:\n",
    "            self.make_dataloader()\n",
    "            self.inspect_data(self.dataloader)\n",
    "\n",
    "    def split_and_make_dataloader(self, train_ratio):\n",
    "        train_size = int(len(self.dataset) * train_ratio)\n",
    "        test_size = len(self.dataset) - train_size\n",
    "        self.train_dataset, self.test_dataset = random_split(self.dataset, [train_size, test_size])\n",
    "\n",
    "        self.train_loader = DataLoader(dataset=self.train_dataset,\n",
    "                                       batch_size=self.batch_size,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=self.num_workers)\n",
    "        self.test_loader = DataLoader(dataset=self.test_dataset,\n",
    "                                      batch_size=self.batch_size,\n",
    "                                      shuffle=False,\n",
    "                                      num_workers=self.num_workers)\n",
    "\n",
    "    def make_dataloader(self):\n",
    "        self.dataloader = DataLoader(dataset=self.dataset,\n",
    "                                     batch_size=self.batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=self.num_workers)\n",
    "        \n",
    "    def inspect_data(self, dataloader):\n",
    "        print(\"Inspecting Data...\")\n",
    "        images, labels = next(iter(dataloader))\n",
    "        print(f\"- Images shape: {images.shape}, Labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78bb6e40-e274-48eb-95a6-77609e97bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 device,\n",
    "                 train_dataloader,\n",
    "                 valid_dataloader,\n",
    "                 loss_fn,\n",
    "                 optimizer,\n",
    "                 scheduler):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.start_time = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "        self.writer = SummaryWriter(log_dir=f'runs/{self.start_time}')\n",
    "\n",
    "    def train_one_epoch(self, epoch, num_epochs, accumulation_steps):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    \n",
    "        for step, (inputs, labels) in enumerate(tqdm(self.train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "    \n",
    "            outputs = self.model(inputs)\n",
    "    \n",
    "            loss = self.loss_fn(outputs, labels) / accumulation_steps\n",
    "            total_loss += loss.item() * accumulation_steps\n",
    "    \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "            loss.backward()\n",
    "            \n",
    "            if (step + 1) % accumulation_steps == 0 or (step + 1) == len(self.train_dataloader):\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "            del inputs, labels, outputs\n",
    "            gc.collect()\n",
    "    \n",
    "        avg_loss = total_loss / len(self.train_dataloader)\n",
    "        accuracy = correct / total  # Calculate accuracy\n",
    "        self.writer.add_scalar(\"Loss/train\", avg_loss, epoch)        \n",
    "        self.writer.add_scalar(\"Accuracy/train\", accuracy, epoch)\n",
    "        self.scheduler.step()\n",
    "\n",
    "    def eval_one_epoch(self, epoch):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.valid_dataloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "\n",
    "                loss = self.loss_fn(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                del inputs, labels, outputs\n",
    "                gc.collect()\n",
    "\n",
    "        avg_loss = total_loss / len(self.valid_dataloader)\n",
    "        accuracy = correct / total\n",
    "        self.writer.add_scalar(\"Loss/valid\", avg_loss, epoch)\n",
    "        self.writer.add_scalar(\"Accuracy/valid\", accuracy, epoch)  \n",
    "        \n",
    "        if avg_loss < self.best_loss:\n",
    "            self.best_loss = avg_loss\n",
    "            torch.save(self.model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "        print(f\"Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    def train(self, num_epochs, accumulation_steps):\n",
    "        start_time = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            self.train_one_epoch(epoch, num_epochs, accumulation_steps)\n",
    "            self.eval_one_epoch(epoch)\n",
    "            \n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcbf7d71-5599-4547-9c63-9f27df2ec40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 610329\n",
      "Inspecting Data...\n",
      "- Images shape: torch.Size([64, 3, 240, 240]), Labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1])\n",
      "Inspecting Data...\n",
      "- Images shape: torch.Size([64, 3, 240, 240]), Labels: tensor([0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "path = 'skin/Camera/Train'\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = ImageDataset(path=path, transform=transform)\n",
    "\n",
    "train_ratio = 0.9\n",
    "batch_size = 64\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "data_loader_maker = DataLoaderMaker(dataset=dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    train_ratio=train_ratio,\n",
    "                                    num_workers=num_workers)\n",
    "\n",
    "train_dataloader = data_loader_maker.train_loader\n",
    "valid_dataloader = data_loader_maker.test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d862ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b1()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 2\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "trainer = ModelTrainer(model=model,\n",
    "                       device=device,\n",
    "                       train_dataloader=train_dataloader,\n",
    "                       valid_dataloader=valid_dataloader,\n",
    "                       loss_fn=loss_fn,\n",
    "                       optimizer=optimizer,\n",
    "                       scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43828f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/96:  28%|██▊       | 2397/8583 [14:34<36:27,  2.83batch/s]"
     ]
    }
   ],
   "source": [
    "trainer.train(96, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d89ab05-4279-403f-b731-23f1f3357d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester:\n",
    "    def __init__(self, path, model, device, dataloader):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.dataloader = dataloader\n",
    "        self.load_weights(path)\n",
    "        self.evaluate()\n",
    "\n",
    "    def load_weights(self, path):\n",
    "        weights = torch.load(path)\n",
    "        self.model.load_state_dict(weights)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def classify(self):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(self.dataloader):\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                labels.extend(targets.cpu().numpy())\n",
    "                \n",
    "        return predictions, labels\n",
    "\n",
    "    def evaluate(self):\n",
    "        predictions, labels = self.classify()\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        precision = precision_score(labels, predictions)\n",
    "        recall = recall_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions)\n",
    "    \n",
    "        print(\"Evaluation Results:\")\n",
    "        print(f\"Confusion Matrix:\\n{cm}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9c16c-eed2-4f98-917f-d76f634d5d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'skin/Camera/Validation'\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = ImageDataset(path=path, transform=transform)\n",
    "\n",
    "train_ratio = 1\n",
    "batch_size = 32\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "data_loader_maker = DataLoaderMaker(dataset=dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    train_ratio=train_ratio,\n",
    "                                    num_workers=num_workers)\n",
    "\n",
    "dataloader = data_loader_maker.dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a3172-7b17-4d78-a6b3-3188c804c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'best_model.pth'\n",
    "model = models.efficientnet_b1()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 2\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "ModelTester(path=path, model=model, device=device, dataloader=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4c4c86-f3df-4be9-96da-519a1ab5210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier:\n",
    "    def __init__(self, device, image_path, image_transform, model_weights_path, model):\n",
    "        self.image_path = image_path\n",
    "        self.image_transform = image_transform\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        self.load_model_weights(model_weights_path)\n",
    "\n",
    "    def preprocess_image(self):\n",
    "        image = Image.open(self.image_path)\n",
    "        input_data = self.image_transform(image).unsqueeze(0)\n",
    "        input_data = input_data.to(self.device)\n",
    "        return input_data\n",
    "\n",
    "    def load_model_weights(self, weights_path):\n",
    "        weights = torch.load(weights_path)\n",
    "        self.model.load_state_dict(weights)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def classify_image(self):\n",
    "        self.model.eval()\n",
    "        input_data = self.preprocess_image()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_data)\n",
    "        \n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "        predicted_prob, predicted_class = torch.max(probabilities, 1)\n",
    "        \n",
    "        class_label = \"Disease\" if predicted_class.item() == 0 else \"Normal\"\n",
    "        class_prob = probabilities[0, predicted_class].item() * 100\n",
    "\n",
    "        print(f\"The image is predicted to be {class_label} with {class_prob:.2f}% probability.\")\n",
    "                \n",
    "        return predicted_class.item(), class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b4ad0-2f24-4da5-a70d-cf700fc9188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "image_path = 'kIHjZsKQ6HdQ.jpg'\n",
    "image_transform = transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "model_weights_path = 'best_model.pth'\n",
    "model = models.efficientnet_b1()\n",
    "num_classes = 2\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "classifier = ImageClassifier(device=device,\n",
    "                             image_path=image_path,\n",
    "                             image_transform=image_transform,\n",
    "                             model_weights_path=model_weights_path,\n",
    "                             model=model)\n",
    "\n",
    "predicted_class = classifier.classify_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7b618-1b79-446a-82d3-afef7c96575b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
