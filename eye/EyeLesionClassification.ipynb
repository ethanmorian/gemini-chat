{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16036efa-cff4-43d6-9044-177bddb959ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaaabab0-360e-408b-b5c9-26cca656d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import pytz\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Sampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "from torchvision import models, transforms\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (confusion_matrix,\n",
    "                             accuracy_score,\n",
    "                             precision_score,\n",
    "                             recall_score,\n",
    "                             f1_score,\n",
    "                             roc_auc_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dbd4be2-139a-4089-9ec2-6c64bd457090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathLabelProcessor:\n",
    "    def __init__(self, base_path, folder_name, pet_type, lesion, devices, symptom):\n",
    "        self.base_path = base_path\n",
    "        self.folder_name = folder_name\n",
    "        self.pet_type = pet_type\n",
    "        self.lesion = lesion\n",
    "        self.devices = devices\n",
    "        self.symptom = symptom\n",
    "\n",
    "        self.label_images()\n",
    "\n",
    "    def find_folders_by_name(self):\n",
    "        matching_folders = []\n",
    "\n",
    "        for root, dirs, files in os.walk(self.base_path):\n",
    "            for dir_name in dirs:\n",
    "                if self.folder_name in dir_name:\n",
    "                    folder_path = os.path.join(root, dir_name)\n",
    "                    matching_folders.append(folder_path)\n",
    "\n",
    "        return matching_folders\n",
    "\n",
    "    def find_image_json_pairs(self, folder_path):\n",
    "        image_paths = []\n",
    "        json_paths = []\n",
    "\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for image_file in filter(lambda x: x.lower().endswith(('jpg', 'png')), files):\n",
    "                image_path = os.path.join(root, image_file)\n",
    "                json_file = f\"{os.path.splitext(image_path)[0]}.json\"\n",
    "                if os.path.isfile(json_file):\n",
    "                    image_paths.append(image_path)\n",
    "                    json_paths.append(json_file)\n",
    "\n",
    "        return image_paths, json_paths\n",
    "\n",
    "    def is_symptomatic(self, data):\n",
    "        return data['label']['label_disease_lv_3'] in self.symptom and data['label']['label_disease_nm'] == self.lesion\n",
    "\n",
    "    def label_images(self):\n",
    "        self.labeled_image_paths = []\n",
    "\n",
    "        for folder_path in self.find_folders_by_name():\n",
    "            image_paths, json_paths = self.find_image_json_pairs(folder_path)\n",
    "\n",
    "            for image_path, json_path in zip(image_paths, json_paths):\n",
    "                with open(json_path) as f:\n",
    "                    data = json.load(f)\n",
    "\n",
    "                if data['images']['meta']['device'] not in self.devices:\n",
    "                    continue\n",
    "\n",
    "                label = 0 if self.is_symptomatic(data) and self.pet_type in os.path.dirname(image_path).lower() else 1\n",
    "                self.labeled_image_paths.append((image_path, label))\n",
    "\n",
    "        symptomatic_count = sum(1 for _, label in self.labeled_image_paths if label == 0)\n",
    "        asymptomatic_count = sum(1 for _, label in self.labeled_image_paths if label == 1)\n",
    "        \n",
    "        weight_class_0 = 1.0 / symptomatic_count\n",
    "        weight_class_1 = 1.0 / asymptomatic_count\n",
    "        self.class_weights = torch.tensor([weight_class_0, weight_class_1])\n",
    "\n",
    "        print(f'Total cases: {len(self.labeled_image_paths)}')\n",
    "        print(f'Number of symptomatic cases: {symptomatic_count}, Number of asymptomatic cases: {asymptomatic_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases: 98646\n",
      "Number of symptomatic cases: 5715, Number of asymptomatic cases: 92931\n",
      "CPU times: user 5.42 s, sys: 1.62 s, total: 7.04 s\n",
      "Wall time: 7.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'eye/Train'\n",
    "folder_name = '일반'\n",
    "'''\n",
    "['유']\n",
    "dog: 안검염, 안검종양, 안검내반증, 유루증, 색소침착성각막염, 핵경화, 결막염\n",
    "cat: 안검염, 결막염, 각막부골편, 비궤양성각막염, 각막궤양\n",
    "['상', '하']\n",
    "dog: 궤양성각막질환, 비궤양성각막질환\n",
    "['초기', '비성숙', '성숙']\n",
    "dog: 백내장\n",
    "'''\n",
    "pet_type = '개'\n",
    "lesion = '안검내반증'\n",
    "devices = ['스마트폰', '일반카메라']\n",
    "symptom = ['유']\n",
    "\n",
    "processor = PathLabelProcessor(base_path=base_path,\n",
    "                               folder_name=folder_name,\n",
    "                               pet_type=pet_type,\n",
    "                               lesion=lesion,\n",
    "                               devices=devices,\n",
    "                               symptom=symptom)\n",
    "\n",
    "data = processor.labeled_image_paths\n",
    "class_weights = processor.class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9ce9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.data[idx]\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class ImageDataset():\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 transform,\n",
    "                 test_size,\n",
    "                 seed,\n",
    "                 batch_size,\n",
    "                 shuffle,\n",
    "                 num_workers):\n",
    "        dataset = self.DatasetMaker(data, transform, test_size, seed)\n",
    "        dataloader = self.DataLoaderMaker(dataset, batch_size, shuffle, num_workers)\n",
    "        \n",
    "        return dataloader\n",
    "        \n",
    "    def DatasetMaker(self, data, transform, test_size=None, seed=42):\n",
    "        if test_size:\n",
    "            train_data, val_data = train_test_split(data, \n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=seed)\n",
    "            dataset_dict = {'train': train_data,\n",
    "                            'val': val_data}\n",
    "            for k, v in dataset_dict.items():\n",
    "                print(f\"- Class Counts for {k}:\")\n",
    "                class_counts = {}\n",
    "                for _, label in v:\n",
    "                    class_counts[label] = class_counts.get(label, 0) + 1\n",
    "                for class_label, count in class_counts.items():\n",
    "                    print(f\"  Class {class_label}: {count} samples\")\n",
    "\n",
    "        dataset = {k: Dataset(v, transform[k])\n",
    "                   for k, v in dataset_dict.items()}\n",
    "        \n",
    "        self.inspect_data(dataset)\n",
    "        \n",
    "        return dataset\n",
    "        \n",
    "    def DataLoaderMaker(self, dataset, batch_size, shuffle, num_workers):\n",
    "        dataloader = {k: DataLoader(dataset=dataset[k],\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=shuffle,\n",
    "                                    num_workers=num_workers,\n",
    "                                    pin_memory=True)\n",
    "                      for k in dataset.keys()}\n",
    "        \n",
    "        self.inspect_data(dataloader)\n",
    "        \n",
    "        return dataloader\n",
    "    \n",
    "    def inspect_data(self, data_dict):\n",
    "        print(\"Inspecting Data...\")\n",
    "\n",
    "        for k, loader in data_dict.items():\n",
    "            class_counts = Counter()\n",
    "            for _, labels in loader:\n",
    "                print(labels)\n",
    "                class_counts.update(labels)\n",
    "\n",
    "            print(f\"- Class Counts for {k}:\")\n",
    "            print(\"Class Counts:\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f60547f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Class Counts for train:\n",
      "  Class 1: 74365 samples\n",
      "  Class 0: 4551 samples\n",
      "- Class Counts for val:\n",
      "  Class 1: 18566 samples\n",
      "  Class 0: 1164 samples\n",
      "Inspecting Data...\n",
      "1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:17\u001b[0m\n",
      "Cell \u001b[0;32mIn[25], line 25\u001b[0m, in \u001b[0;36mImageDataset.__init__\u001b[0;34m(self, data, transform, test_size, seed, batch_size, shuffle, num_workers)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     18\u001b[0m              data,\n\u001b[1;32m     19\u001b[0m              transform,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m              shuffle,\n\u001b[1;32m     24\u001b[0m              num_workers):\n\u001b[0;32m---> 25\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDatasetMaker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDataLoaderMaker(dataset, batch_size, shuffle, num_workers)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataloader\n",
      "Cell \u001b[0;32mIn[25], line 48\u001b[0m, in \u001b[0;36mImageDataset.DatasetMaker\u001b[0;34m(self, data, transform, test_size, seed)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m dataset \u001b[38;5;241m=\u001b[39m {k: Dataset(v, transform[k])\n\u001b[1;32m     46\u001b[0m            \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m dataset_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minspect_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "Cell \u001b[0;32mIn[25], line 71\u001b[0m, in \u001b[0;36mImageDataset.inspect_data\u001b[0;34m(self, data_dict)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, labels \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(labels)\n\u001b[0;32m---> 71\u001b[0m     \u001b[43mclass_counts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Class Counts for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass Counts:\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_counts)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/collections/__init__.py:670\u001b[0m, in \u001b[0;36mCounter.update\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate(iterable)\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m         \u001b[43m_count_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds:\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = {'train': transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomVerticalFlip(),\n",
    "                                          transforms.RandomRotation(degrees=10),\n",
    "                                          transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]),\n",
    "             'val': transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])}\n",
    "test_size = 0.2\n",
    "seed = 42\n",
    "batch_size = 96\n",
    "shuffle = True\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "dataloader = ImageDataset(data=data,\n",
    "                          transform=transform,\n",
    "                          test_size=test_size,\n",
    "                          seed=seed,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=shuffle,\n",
    "                          num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d4e9f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Class Counts for train:\n",
      "  Class 1: 74319 samples\n",
      "  Class 0: 4597 samples\n",
      "- Class Counts for val:\n",
      "  Class 1: 18612 samples\n",
      "  Class 0: 1118 samples\n",
      "CPU times: user 54.2 ms, sys: 23.4 ms, total: 77.5 ms\n",
      "Wall time: 74.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = {'train': transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomVerticalFlip(),\n",
    "                                          transforms.RandomRotation(degrees=10),\n",
    "                                          transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]),\n",
    "             'val': transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])}\n",
    "\n",
    "dataset = DatasetMaker(data=labeled_image_paths,\n",
    "                       transform=transform,\n",
    "                       test_size=0.2,\n",
    "                       seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35964a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoaderMaker(dataset, batch_size, shuffle, num_workers):\n",
    "    dataloader = {k: DataLoader(dataset=dataset[k],\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=shuffle,\n",
    "                                num_workers=num_workers,\n",
    "                                pin_memory=True)\n",
    "                  for k in dataset.keys()}\n",
    "    \n",
    "    print(\"Inspecting Data...\")\n",
    "\n",
    "    class_counts = {}\n",
    "    for k, loader in dataloader.items():\n",
    "        for _, labels in loader:\n",
    "            for label in labels.tolist():\n",
    "                class_counts[label] = class_counts.get(label, 0) + 1\n",
    "\n",
    "        print(f\"- Class Counts for {k}:\")\n",
    "        for class_label, count in class_counts.items():\n",
    "            print(f\"  Class {class_label}: {count} samples\")\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "971ddedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Class Counts for train:\n",
      "  Class 1: 74319 samples\n",
      "  Class 0: 4597 samples\n",
      "- Class Counts for val:\n",
      "  Class 1: 92931 samples\n",
      "  Class 0: 5715 samples\n",
      "CPU times: user 17 s, sys: 15.7 s, total: 32.7 s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 96\n",
    "shuffle = True\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "dataloader = DataLoaderMaker(dataset=dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=shuffle,\n",
    "                             num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "031abb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, labeled_image_paths, transform):\n",
    "        self.labeled_image_paths = labeled_image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "        self.labels = [label for _, label in labeled_image_paths]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labeled_image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.labeled_image_paths[idx]\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.7 ms, sys: 92.4 ms, total: 118 ms\n",
      "Wall time: 113 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = {'train': transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                          transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomVerticalFlip(),\n",
    "                                          transforms.RandomRotation(degrees=10),\n",
    "                                          transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]),\n",
    "             'val': transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])}\n",
    "\n",
    "dataset = ImageDataset(labeled_image_paths=labeled_image_paths,\n",
    "                       transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5ce73a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderMaker:\n",
    "    def __init__(self, dataset, batch_size, train_ratio=None, num_workers=None):\n",
    "        self.dataset = dataset\n",
    "        self.train_ratio = train_ratio\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        if train_ratio:\n",
    "            self.split_and_make_dataloader()\n",
    "        else:\n",
    "            self.dataloader = self.make_dataloader(self.dataset)\n",
    "\n",
    "    def make_dataloader(self, dataset, shuffle=False):\n",
    "        dataloader = DataLoader(dataset=dataset,\n",
    "                                batch_size=self.batch_size,\n",
    "                                shuffle=shuffle,\n",
    "                                num_workers=self.num_workers,\n",
    "                                pin_memory=True)\n",
    "        \n",
    "        self.inspect_data(dataloader)\n",
    "        \n",
    "        return dataloader\n",
    "\n",
    "    def split_and_make_dataloader(self):\n",
    "        train_size = int(len(self.dataset) * self.train_ratio)\n",
    "        test_size = len(self.dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(self.dataset, [train_size, test_size])\n",
    "\n",
    "        self.train_loader = self.make_dataloader(train_dataset, shuffle=True)\n",
    "        self.test_loader = self.make_dataloader(test_dataset, shuffle=True)\n",
    "\n",
    "    def inspect_data(self, dataloader):\n",
    "        print(\"Inspecting Data...\")\n",
    "\n",
    "        class_counts = {}\n",
    "        for _, labels in dataloader:\n",
    "            for label in labels.tolist():\n",
    "                class_counts[label] = class_counts.get(label, 0) + 1\n",
    "\n",
    "        print(\"- Class Counts:\")\n",
    "        for class_label, count in class_counts.items():\n",
    "            print(f\"  Class {class_label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c50950d-8c44-4221-b4e2-915222bf9d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 364, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 364, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"/tmp/ipykernel_2100428/2975926141.py\", line 15, in __getitem__\n    image = self.transform(image)\nTypeError: 'dict' object is not callable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:5\u001b[0m\n",
      "Cell \u001b[0;32mIn[44], line 9\u001b[0m, in \u001b[0;36mDataLoaderMaker.__init__\u001b[0;34m(self, dataset, batch_size, train_ratio, num_workers)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers \u001b[38;5;241m=\u001b[39m num_workers\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_ratio:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit_and_make_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataloader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)\n",
      "Cell \u001b[0;32mIn[44], line 29\u001b[0m, in \u001b[0;36mDataLoaderMaker.split_and_make_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m val_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset) \u001b[38;5;241m-\u001b[39m train_size\n\u001b[1;32m     27\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m random_split(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, [train_size, val_size])\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataloader(val_dataset)\n",
      "Cell \u001b[0;32mIn[44], line 20\u001b[0m, in \u001b[0;36mDataLoaderMaker.make_dataloader\u001b[0;34m(self, dataset, shuffle)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_dataloader\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     14\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m     15\u001b[0m                             batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m     16\u001b[0m                             shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[1;32m     17\u001b[0m                             num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers,\n\u001b[1;32m     18\u001b[0m                             pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minspect_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataloader\n",
      "Cell \u001b[0;32mIn[44], line 36\u001b[0m, in \u001b[0;36mDataLoaderMaker.inspect_data\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInspecting Data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m labels\u001b[38;5;241m.\u001b[39mtolist():\n\u001b[1;32m     38\u001b[0m         class_counts[label] \u001b[38;5;241m=\u001b[39m class_counts\u001b[38;5;241m.\u001b[39mget(label, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 364, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 364, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"/tmp/ipykernel_2100428/2975926141.py\", line 15, in __getitem__\n    image = self.transform(image)\nTypeError: 'dict' object is not callable\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 96\n",
    "num_workers = os.cpu_count()\n",
    "train_ratio = 0.8\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              train_ratio=train_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0b2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 device,\n",
    "                 train_dataloader,\n",
    "                 valid_dataloader,\n",
    "                 criterion,\n",
    "                 optimizer,\n",
    "                 scheduler,\n",
    "                 pet_type,\n",
    "                 lesion):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.criterion = criterion.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.best_f1_score = 0.0\n",
    "        korea = pytz.timezone('Asia/Seoul')\n",
    "        now = datetime.now(korea)\n",
    "        start_time = now.strftime('%Y%m%d-%H%M%S')\n",
    "        self.name = f'{start_time}_{pet_type}_{lesion}.pth'\n",
    "        self.writer = SummaryWriter(log_dir=f'runs/{self.name}')\n",
    "\n",
    "    def calculate_f1_score(self, predicted, labels):\n",
    "        return f1_score(labels, predicted, average='binary')\n",
    "\n",
    "    def calculate_auc_roc(self, predicted, labels):\n",
    "        return roc_auc_score(labels, predicted)\n",
    "\n",
    "    def run_epoch(self, epoch, num_epochs, phase='train'):\n",
    "        self.model.train() if phase == 'train' else self.model.eval()\n",
    "        dataloader = self.train_dataloader if phase == 'train' else self.valid_dataloader\n",
    "\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_predicted = []\n",
    "        all_labels = []\n",
    "\n",
    "        for inputs, labels in tqdm(dataloader, desc=f'{phase.capitalize()} Epoch {epoch + 1}/{num_epochs}', unit='batch'):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                all_predicted.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        accuracy = correct / total\n",
    "        self.writer.add_scalar(f'Loss/{phase}', avg_loss, epoch)\n",
    "        self.writer.add_scalar(f'Accuracy/{phase}', accuracy, epoch)\n",
    "\n",
    "        if phase == 'val':\n",
    "            current_f1_score = self.calculate_f1_score(np.array(all_predicted), np.array(all_labels))\n",
    "            current_auc_roc = self.calculate_auc_roc(np.array(all_predicted), np.array(all_labels))\n",
    "\n",
    "            self.writer.add_scalar('F1 Score/valid', current_f1_score, epoch)\n",
    "            self.writer.add_scalar('AUC-ROC/valid', current_auc_roc, epoch)\n",
    "\n",
    "            if current_f1_score > self.best_f1_score:\n",
    "                self.best_f1_score = current_f1_score\n",
    "                torch.save(self.model, self.name)\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.run_epoch(epoch, num_epochs, 'train')\n",
    "            self.run_epoch(epoch, num_epochs, 'val')\n",
    "\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 device,\n",
    "                 train_dataloader,\n",
    "                 valid_dataloader,\n",
    "                 criterion,\n",
    "                 optimizer,\n",
    "                 scheduler,\n",
    "                 pet_type,\n",
    "                 lesion):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.criterion = criterion.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.best_f1_score = 0.0\n",
    "        korea = pytz.timezone('Asia/Seoul')\n",
    "        now = datetime.now(korea)\n",
    "        start_time = now.strftime('%Y%m%d-%H%M%S')\n",
    "        self.name = f'{start_time}_{pet_type}_{lesion}.pth'\n",
    "        self.writer = SummaryWriter(log_dir=f'runs/{self.name}')\n",
    "\n",
    "    def calculate_f1_score(self, predicted, labels):\n",
    "        return f1_score(labels, predicted, average='binary')\n",
    "\n",
    "    def calculate_auc_roc(self, predicted, labels):\n",
    "        return roc_auc_score(labels, predicted)\n",
    "\n",
    "    def train_one_epoch(self, epoch, num_epochs):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    \n",
    "        for step, (inputs, labels) in enumerate(tqdm(self.train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "    \n",
    "            outputs = self.model(inputs)\n",
    "            \n",
    "            loss = self.criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "            loss.backward()\n",
    "    \n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "    \n",
    "        self.scheduler.step()\n",
    "        self.writer.add_scalar('LearningRate',\n",
    "                               self.scheduler.get_last_lr()[0],\n",
    "                               epoch)\n",
    "    \n",
    "        avg_loss = total_loss / len(self.train_dataloader)\n",
    "        accuracy = correct / total\n",
    "        self.writer.add_scalar('Loss/train', avg_loss, epoch)        \n",
    "        self.writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
    "\n",
    "    def eval_one_epoch(self, epoch):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_predicted = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.valid_dataloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "        \n",
    "                outputs = self.model(inputs)\n",
    "        \n",
    "                loss = self.criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "        \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "                all_predicted.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(self.valid_dataloader)\n",
    "        accuracy = correct / total\n",
    "        self.writer.add_scalar('Loss/valid', avg_loss, epoch)\n",
    "        self.writer.add_scalar('Accuracy/valid', accuracy, epoch)\n",
    "        \n",
    "        current_f1_score = self.calculate_f1_score(np.array(all_predicted),\n",
    "                                                   np.array(all_labels))\n",
    "        current_auc_roc = self.calculate_auc_roc(np.array(all_predicted),\n",
    "                                                 np.array(all_labels))\n",
    "        \n",
    "        self.writer.add_scalar('F1 Score/valid', current_f1_score, epoch)\n",
    "        self.writer.add_scalar('AUC-ROC/valid', current_auc_roc, epoch)\n",
    "        \n",
    "        if current_f1_score > self.best_f1_score:\n",
    "            self.best_f1_score = current_f1_score\n",
    "            torch.save(self.model, self.name)\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train_one_epoch(epoch, num_epochs)\n",
    "            self.eval_one_epoch(epoch)\n",
    "            \n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69d9bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = targets.to(inputs.device)\n",
    "        \n",
    "        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            # Move alpha to the same device as inputs\n",
    "            self.alpha = self.alpha.to(inputs.device)\n",
    "            focal_loss = self.alpha[targets] * focal_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        elif self.reduction == 'none':\n",
    "            return focal_loss\n",
    "        else:\n",
    "            raise ValueError(\"Invalid reduction option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e89e25-1427-4de0-bf41-fcb94349cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b1(pretrained=True)\n",
    "for name, param in model.named_parameters():\n",
    "    if \"last_layer\" not in name:\n",
    "        param.requires_grad = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "num_classes = 2\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "criterion = FocalLoss(gamma=2, alpha=class_weights, reduction='sum')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "trainer = ModelTrainer(model=model,\n",
    "                       device=device,\n",
    "                       train_dataloader=data_loader.train_loader,\n",
    "                       valid_dataloader=data_loader.test_loader,\n",
    "                       criterion=criterion,\n",
    "                       optimizer=optimizer,\n",
    "                       scheduler=scheduler,\n",
    "                       pet_type=pet_type,\n",
    "                       lesion=lesion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "397f7da3-9b44-4ecf-8c4a-43dfd0fa71e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 823/823 [06:59<00:00,  1.96batch/s]\n",
      "Epoch 2/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 3/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 4/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 5/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 6/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 7/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 8/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 9/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 10/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 11/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 12/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 13/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 14/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 15/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 16/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 17/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 18/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 19/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 20/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 21/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 22/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 23/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 24/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 25/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 26/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 27/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 28/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 29/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 30/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4dac2b9-a8a2-4577-8972-126d23e2a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester:\n",
    "    def __init__(self, path, device, dataloader):\n",
    "        self.device = device\n",
    "        self.dataloader = dataloader\n",
    "        self.load_model(path)\n",
    "        self.evaluate()\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = torch.load(path)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def classify(self):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(self.dataloader):\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                labels.extend(targets.cpu().numpy())\n",
    "                probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "        return predictions, labels, probabilities\n",
    "\n",
    "    def calculate_prob_stats(self, probabilities):\n",
    "        probabilities = np.array(probabilities)\n",
    "        min_probs = np.min(probabilities)\n",
    "        max_probs = np.max(probabilities)\n",
    "        std_probs = np.std(probabilities)\n",
    "        mean_probs = np.mean(probabilities)\n",
    "\n",
    "        return min_probs, max_probs, std_probs, mean_probs\n",
    "\n",
    "    def calculate_percentage(self, value):\n",
    "        return f'{value*100:.2f}%'\n",
    "\n",
    "    def evaluate(self):\n",
    "        predictions, labels, probabilities = self.classify()\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "        min_probs, max_probs, std_probs, mean_probs = self.calculate_prob_stats(probabilities)\n",
    "\n",
    "        print('Evaluation Results:')\n",
    "        print(f'Confusion Matrix:\\n{cm}')\n",
    "        print(f'Accuracy: {self.calculate_percentage(accuracy)}')\n",
    "        print(f'F1 Score: {self.calculate_percentage(f1)}')\n",
    "        print(f'Mean Probability: {self.calculate_percentage(mean_probs)}')\n",
    "        print(f'Max Probability: {self.calculate_percentage(max_probs)}')\n",
    "        print(f'Min Probability: {self.calculate_percentage(min_probs)}')\n",
    "        print(f'Standard Deviation of Probabilities: {std_probs:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62042bbe-8452-4cbb-9cbc-106474e8b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cases: 13808\n",
      "Number of symptomatic cases: 1023, Number of asymptomatic cases: 12785\n",
      "CPU times: user 838 ms, sys: 308 ms, total: 1.15 s\n",
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'eye/Valid'\n",
    "folder_name = '일반'\n",
    "'''\n",
    "['유']\n",
    "dog: 안검염, 안검종양, 안검내반증, 유루증, 색소침착성각막염, 핵경화, 결막염\n",
    "cat: 안검염, 결막염, 각막부골편, 비궤양성각막염, 각막궤양\n",
    "['상', '하']\n",
    "dog: 궤양성각막질환, 비궤양성각막질환\n",
    "['초기', '비성숙', '성숙']\n",
    "dog: 백내장\n",
    "'''\n",
    "pet_type = '개'\n",
    "lesion = '안검내반증'\n",
    "devices = ['스마트폰', '일반카메라']\n",
    "symptom = ['유']\n",
    "\n",
    "processor = PathLabelProcessor(base_path=base_path,\n",
    "                               folder_name=folder_name,\n",
    "                               pet_type=pet_type,\n",
    "                               lesion=lesion,\n",
    "                               devices=devices,\n",
    "                               symptom=symptom)\n",
    "\n",
    "labeled_image_paths = processor.labeled_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6b4f548-c460-4b57-9dfd-aab096b8e5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Class Counts:\n",
      "  Class 1: 12785 samples\n",
      "  Class 0: 1023 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432/432 [00:20<00:00, 21.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[    2  1021]\n",
      " [   15 12770]]\n",
      "Accuracy: 92.50%\n",
      "F1 Score: 89.01%\n",
      "Mean Probability: 50.00%\n",
      "Max Probability: 97.77%\n",
      "Min Probability: 2.23%\n",
      "Standard Deviation of Probabilities: 0.3940\n",
      "CPU times: user 24.8 s, sys: 6.22 s, total: 31 s\n",
      "Wall time: 27.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fa9631ba140>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([transforms.Resize((240, 240))])\n",
    "\n",
    "dataset = ImageDataset(labeled_image_paths=labeled_image_paths,\n",
    "                       transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "path = '20231212-215730_개_안검내반증.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ac4fc64-78f1-4f13-a8a1-24db74dcff98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n",
      "- Class Counts:\n",
      "  Class 0: 1023 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:02<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[   2 1021]\n",
      " [   0    0]]\n",
      "Accuracy: 0.20%\n",
      "F1 Score: 0.39%\n",
      "Mean Probability: 50.00%\n",
      "Max Probability: 92.84%\n",
      "Min Probability: 7.16%\n",
      "Standard Deviation of Probabilities: 0.3223\n",
      "CPU times: user 1.98 s, sys: 1.44 s, total: 3.42 s\n",
      "Wall time: 3.75 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fa805bd2aa0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(labeled_image_paths=[item for item in labeled_image_paths if item[1] == 0],\n",
    "                       transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbd26772-e67c-4dbc-a8e3-130455e3893e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Class Counts:\n",
      "  Class 1: 12785 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:18<00:00, 21.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[    0     0]\n",
      " [   15 12770]]\n",
      "Accuracy: 99.88%\n",
      "F1 Score: 99.94%\n",
      "Mean Probability: 50.00%\n",
      "Max Probability: 97.77%\n",
      "Min Probability: 2.23%\n",
      "Standard Deviation of Probabilities: 0.3992\n",
      "CPU times: user 23.1 s, sys: 5.74 s, total: 28.8 s\n",
      "Wall time: 26.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fa9631ba0e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(labeled_image_paths=[item for item in labeled_image_paths if item[1] == 1],\n",
    "                       transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreModelTester:\n",
    "    def __init__(self, path, device, dataloader):\n",
    "        self.device = device\n",
    "        self.dataloader = dataloader\n",
    "        self.model = models.vgg16_bn(pretrained=True)\n",
    "        self.load_model(path)\n",
    "        self.evaluate()\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = models.vgg16_bn(pretrained=True)\n",
    "        nr_filters = self.model.classifier[0].in_features\n",
    "        self.model.classifier = nn.Linear(nr_filters, 1)\n",
    "        state_dict = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "        model_dict = self.model.state_dict()\n",
    "        state_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
    "        model_dict.update(state_dict)\n",
    "        self.model.load_state_dict(model_dict)\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "    def classify(self):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(self.dataloader):\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                labels.extend(targets.cpu().numpy())\n",
    "                probabilities.extend(probs.max(dim=1).values.cpu().numpy())\n",
    "\n",
    "        return predictions, labels, probabilities\n",
    "\n",
    "    def calculate_prob_stats(self, probabilities):\n",
    "        probabilities = np.array(probabilities)\n",
    "        min_probs = np.min(probabilities)\n",
    "        max_probs = np.max(probabilities)\n",
    "        std_probs = np.std(probabilities)\n",
    "        mean_probs = np.mean(probabilities)\n",
    "\n",
    "        return min_probs, max_probs, std_probs, mean_probs\n",
    "\n",
    "    def evaluate(self):\n",
    "        predictions, labels, probabilities = self.classify()\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "        min_probs, max_probs, std_probs, mean_probs = self.calculate_prob_stats(probabilities)\n",
    "\n",
    "        print(\"Evaluation Results:\")\n",
    "        print(f\"Confusion Matrix:\\n{cm}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"Mean Probability: {mean_probs:.4f}\")\n",
    "        print(f\"Max Probability: {max_probs:.4f}\")\n",
    "        print(f\"Min Probability: {min_probs:.4f}\")        \n",
    "        print(f\"Standard Deviation of Probabilities: {std_probs:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(labeled_image_paths=labeled_image_paths,\n",
    "                       transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "path = 'pre_eye.pt'\n",
    "\n",
    "PreModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(\n",
    "    labeled_image_paths=labeled_image_paths,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "PreModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(\n",
    "    labeled_image_paths=labeled_image_paths,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "PreModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
