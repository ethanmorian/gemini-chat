{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16036efa-cff4-43d6-9044-177bddb959ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaaabab0-360e-408b-b5c9-26cca656d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from collections import Counter\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models, transforms\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dbd4be2-139a-4089-9ec2-6c64bd457090",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathLabelProcessor:\n",
    "    def __init__(self, \n",
    "                 base_path,\n",
    "                 folder_name,\n",
    "                 pet_type,\n",
    "                 lesion,\n",
    "                 devices,\n",
    "                 symptom):\n",
    "        self.base_path = base_path\n",
    "        self.folder_name = folder_name\n",
    "        self.pet_type = pet_type\n",
    "        self.lesion = lesion\n",
    "        self.devices = devices\n",
    "        self.symptom = symptom\n",
    "        \n",
    "        self.label_images()\n",
    "        \n",
    "    def find_folders_by_name(self):\n",
    "        matching_folders = []\n",
    "\n",
    "        for root, dirs, files in os.walk(self.base_path):\n",
    "            for dir_name in dirs:\n",
    "                if self.folder_name in dir_name:\n",
    "                    folder_path = os.path.join(root, dir_name)\n",
    "                    matching_folders.append(folder_path)\n",
    "\n",
    "        for folder_path in matching_folders:\n",
    "            print(folder_path)\n",
    "            \n",
    "        return matching_folders\n",
    "\n",
    "    def find_image_json_pairs(self):\n",
    "        image_paths = []\n",
    "        json_paths = []\n",
    "\n",
    "        for folder_path in self.find_folders_by_name():\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for image_file in filter(lambda x: x.lower().endswith(('jpg', 'png')), files):\n",
    "                    image_path = os.path.join(root, image_file)\n",
    "                    json_file = f\"{os.path.splitext(image_path)[0]}.json\"\n",
    "                    if os.path.isfile(json_file):\n",
    "                        image_paths.append(image_path)\n",
    "                        json_paths.append(json_file)\n",
    "\n",
    "        print(f'Total images: {len(image_paths)}, Total JSON files: {len(json_paths)}')\n",
    "        \n",
    "        return image_paths, json_paths\n",
    "\n",
    "    def label_images(self):\n",
    "        self.labeled_image_paths = []\n",
    "\n",
    "        for image_path, json_path in zip(*self.find_image_json_pairs()):\n",
    "            with open(json_path) as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            is_symptomatic = data['label']['label_disease_lv_3'] in self.symptom and data['label']['label_disease_nm'] == self.lesion\n",
    "\n",
    "            if data['images']['meta']['device'] in self.devices:\n",
    "                if self.pet_type in os.path.dirname(image_path).lower():\n",
    "                    self.labeled_image_paths.append((image_path, 0 if is_symptomatic else 1))\n",
    "                else:\n",
    "                    self.labeled_image_paths.append((image_path, 1))\n",
    "        \n",
    "        self.symptomatic_count = len(Counter(item for item in self.labeled_image_paths if item[1] == 0))\n",
    "        self.asymptomatic_count = len(Counter(item for item in self.labeled_image_paths if item[1] == 1))\n",
    "\n",
    "        print(f'Total cases: {len(self.labeled_image_paths)}')\n",
    "        print(f'Number of symptomatic cases: {self.symptomatic_count}, Number of asymptomatic cases: {self.asymptomatic_count}')\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, labeled_image_paths, transform):\n",
    "        self.labeled_image_paths = labeled_image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labeled_image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.labeled_image_paths[idx]\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "class DataLoaderMaker:\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 batch_size,\n",
    "                 train_ratio=0,\n",
    "                 num_workers=None):\n",
    "        self.dataset = dataset\n",
    "        self.train_ratio = train_ratio\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        if train_ratio:\n",
    "            self.split_and_make_dataloader()\n",
    "        else:\n",
    "            self.dataloader = self.make_dataloader(self.dataset)\n",
    "\n",
    "    def make_dataloader(self, dataset, shuffle=False):\n",
    "        dataloader = DataLoader(dataset=dataset,\n",
    "                                batch_size=self.batch_size,\n",
    "                                shuffle=shuffle,\n",
    "                                num_workers=self.num_workers,\n",
    "                                pin_memory=True)\n",
    "        \n",
    "        self.inspect_data(dataloader)\n",
    "        \n",
    "        return dataloader\n",
    "\n",
    "    def split_and_make_dataloader(self):\n",
    "        train_size = int(len(self.dataset) * self.train_ratio)\n",
    "        test_size = len(self.dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(self.dataset, [train_size, test_size])\n",
    "\n",
    "        self.train_loader = self.make_dataloader(train_dataset, shuffle=True)\n",
    "        self.test_loader = self.make_dataloader(test_dataset, shuffle=True)\n",
    "\n",
    "    def inspect_data(self, dataloader):\n",
    "        print(\"Inspecting Data...\")\n",
    "\n",
    "        class_counts = {}\n",
    "        for _, labels in dataloader:\n",
    "            labels = labels.type(torch.int)\n",
    "            for label in labels.tolist():\n",
    "                class_counts[label] = class_counts.get(label, 0) + 1\n",
    "\n",
    "        print(\"- Class Counts:\")\n",
    "        for class_label, count in class_counts.items():\n",
    "            print(f\"  Class {class_label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eye/Train/고양이/안구/일반\n",
      "eye/Train/개/안구/일반\n",
      "Total images: 199816, Total JSON files: 199816\n",
      "Total cases: 98646\n",
      "Number of symptomatic cases: 52, Number of asymptomatic cases: 98594\n",
      "CPU times: user 5.85 s, sys: 1.54 s, total: 7.39 s\n",
      "Wall time: 7.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'eye/Train'\n",
    "folder_name = '일반'\n",
    "'''\n",
    "['유']\n",
    "dog: 안검염, 안검종양, 안검내반증, 유루증, 색소침착성각막염, 핵경화, 결막염\n",
    "cat: 안검염, 결막염, 각막부골편, 비궤양성각막염, 각막궤양\n",
    "['상', '하']\n",
    "dog: 궤양성각막질환, 비궤양성각막질환\n",
    "['초기', '비성숙', '성숙']\n",
    "dog: 백내장\n",
    "'''\n",
    "pet_type = '개'\n",
    "lesion = '안검종양'\n",
    "devices = ['스마트폰', '일반카메라']\n",
    "symptom = ['유']\n",
    "\n",
    "processor = PathLabelProcessor(base_path=base_path,\n",
    "                               folder_name=folder_name,\n",
    "                               pet_type=pet_type,\n",
    "                               lesion=lesion,\n",
    "                               devices=devices,\n",
    "                               symptom=symptom)\n",
    "\n",
    "labeled_image_paths = processor.labeled_image_paths\n",
    "weight_class_0 = 1.0 / processor.symptomatic_count\n",
    "weight_class_1 = 1.0 / processor.asymptomatic_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3222\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3221\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3222\u001b[0m     fp\u001b[39m.\u001b[39;49mseek(\u001b[39m0\u001b[39m)\n\u001b[1;32m   3223\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, io\u001b[39m.\u001b[39mUnsupportedOperation):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:17\u001b[0m\n",
      "\u001b[1;32mc:\\Git\\drharu\\eye\\EyeLesionClassification.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#W5sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m class_labels_counter \u001b[39m=\u001b[39m Counter(label \u001b[39mfor\u001b[39;00m _, label \u001b[39min\u001b[39;00m labeled_image_paths)\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#W5sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mminority_class \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(class_labels_counter, key\u001b[39m=\u001b[39mclass_labels_counter\u001b[39m.\u001b[39mget)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#W5sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moversample_minority_class(num_samples\u001b[39m=\u001b[39;49mnum_samples)\n",
      "\u001b[1;32mc:\\Git\\drharu\\eye\\EyeLesionClassification.ipynb Cell 6\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#W5sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_samples):\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#W5sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     \u001b[39mfor\u001b[39;00m image_path, label \u001b[39min\u001b[39;00m minority_samples:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#W5sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m         tensor_image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_to_tensor_and_clone(image_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#W5sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabeled_image_paths\u001b[39m.\u001b[39mappend((tensor_image, label))\n",
      "\u001b[1;32mc:\\Git\\drharu\\eye\\EyeLesionClassification.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#W5sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform_to_tensor_and_clone\u001b[39m(\u001b[39mself\u001b[39m, image_path):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#W5sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     image_tensor \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mToTensor()(Image\u001b[39m.\u001b[39;49mopen(image_path))\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#W5sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m     tensor_image \u001b[39m=\u001b[39m image_tensor\u001b[39m.\u001b[39mclone()\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#W5sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor_image\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3224\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3222\u001b[0m     fp\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n\u001b[1;32m   3223\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, io\u001b[39m.\u001b[39mUnsupportedOperation):\n\u001b[0;32m-> 3224\u001b[0m     fp \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO(fp\u001b[39m.\u001b[39;49mread())\n\u001b[1;32m   3225\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   3227\u001b[0m prefix \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39mread(\u001b[39m16\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = ImageDataset(labeled_image_paths=labeled_image_paths,\n",
    "                       transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50950d-8c44-4221-b4e2-915222bf9d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/PIL/Image.py\", line 3222, in open\n    fp.seek(0)\nAttributeError: 'Tensor' object has no attribute 'seek'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 364, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 364, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"/tmp/ipykernel_2086027/1626559996.py\", line 87, in __getitem__\n    image = Image.open(image_path)\n  File \"/opt/conda/lib/python3.10/site-packages/PIL/Image.py\", line 3224, in open\n    fp = io.BytesIO(fp.read())\nAttributeError: 'Tensor' object has no attribute 'read'. Did you mean: 'real'?\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:5\u001b[0m\n",
      "\u001b[1;32mc:\\Git\\drharu\\eye\\EyeLesionClassification.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers \u001b[39m=\u001b[39m num_workers\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m \u001b[39mif\u001b[39;00m train_ratio:\n\u001b[0;32m--> <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplit_and_make_dataloader()\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataloader(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset)\n",
      "\u001b[1;32mc:\\Git\\drharu\\eye\\EyeLesionClassification.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m test_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset) \u001b[39m-\u001b[39m train_size\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m train_dataset, test_dataset \u001b[39m=\u001b[39m random_split(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, [train_size, test_size])\n\u001b[0;32m--> <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_dataloader(train_dataset, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_loader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataloader(test_dataset, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Git\\drharu\\eye\\EyeLesionClassification.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_dataloader\u001b[39m(\u001b[39mself\u001b[39m, dataset, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m     dataloader \u001b[39m=\u001b[39m DataLoader(dataset\u001b[39m=\u001b[39mdataset,\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m                             batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size,\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m                             shuffle\u001b[39m=\u001b[39mshuffle,\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m                             num_workers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers,\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m                             pin_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=127'>128</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minspect_data(dataloader)\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m dataloader\n",
      "\u001b[1;32mc:\\Git\\drharu\\eye\\EyeLesionClassification.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInspecting Data...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m class_counts \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m \u001b[39mfor\u001b[39;00m _, labels \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=144'>145</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mint)\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeLesionClassification.ipynb#X10sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m     \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m labels\u001b[39m.\u001b[39mtolist():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/PIL/Image.py\", line 3222, in open\n    fp.seek(0)\nAttributeError: 'Tensor' object has no attribute 'seek'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 364, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 364, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"/tmp/ipykernel_2086027/1626559996.py\", line 87, in __getitem__\n    image = Image.open(image_path)\n  File \"/opt/conda/lib/python3.10/site-packages/PIL/Image.py\", line 3224, in open\n    fp = io.BytesIO(fp.read())\nAttributeError: 'Tensor' object has no attribute 'read'. Did you mean: 'real'?\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 96\n",
    "num_workers = os.cpu_count()\n",
    "train_ratio = 0.8\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              train_ratio=train_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 device,\n",
    "                 train_dataloader,\n",
    "                 valid_dataloader,\n",
    "                 loss_fn,\n",
    "                 optimizer,\n",
    "                 scheduler,\n",
    "                 pet_type,\n",
    "                 lesion):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.loss_fn = loss_fn.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.best_f1_score = 0.0\n",
    "        korea = pytz.timezone('Asia/Seoul')\n",
    "        now = datetime.now(korea)\n",
    "        start_time = now.strftime('%Y%m%d-%H%M%S')\n",
    "        self.name = f'{start_time}_{pet_type}_{lesion}.pth'\n",
    "        self.writer = SummaryWriter(log_dir=f'runs/{self.name}')\n",
    "\n",
    "    def calculate_f1_score(self, predicted, labels):\n",
    "        return f1_score(labels, predicted, average='binary')\n",
    "\n",
    "    def calculate_auc_roc(self, predicted, labels):\n",
    "        return roc_auc_score(labels, predicted)\n",
    "\n",
    "    def train_one_epoch(self, epoch, num_epochs):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    \n",
    "        for step, (inputs, labels) in enumerate(tqdm(self.train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "    \n",
    "            outputs = self.model(inputs)\n",
    "            \n",
    "            loss = self.loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "            loss.backward()\n",
    "    \n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "    \n",
    "        self.scheduler.step()\n",
    "        self.writer.add_scalar('LearningRate', self.scheduler.get_last_lr()[0], epoch)\n",
    "    \n",
    "        avg_loss = total_loss / len(self.train_dataloader)\n",
    "        accuracy = correct / total\n",
    "        self.writer.add_scalar('Loss/train', avg_loss, epoch)        \n",
    "        self.writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
    "\n",
    "    def eval_one_epoch(self, epoch):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_predicted = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.valid_dataloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "        \n",
    "                outputs = self.model(inputs)\n",
    "        \n",
    "                loss = self.loss_fn(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "        \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "                all_predicted.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(self.valid_dataloader)\n",
    "        accuracy = correct / total\n",
    "        self.writer.add_scalar('Loss/valid', avg_loss, epoch)\n",
    "        self.writer.add_scalar('Accuracy/valid', accuracy, epoch)\n",
    "        \n",
    "        current_f1_score = self.calculate_f1_score(np.array(all_predicted), np.array(all_labels))\n",
    "        current_auc_roc = self.calculate_auc_roc(np.array(all_predicted), np.array(all_labels))\n",
    "        \n",
    "        self.writer.add_scalar('F1 Score/valid', current_f1_score, epoch)\n",
    "        self.writer.add_scalar('AUC-ROC/valid', current_auc_roc, epoch)\n",
    "        \n",
    "        if current_f1_score > self.best_f1_score:\n",
    "            self.best_f1_score = current_f1_score\n",
    "            torch.save(self.model, self.name)\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train_one_epoch(epoch, num_epochs)\n",
    "            self.eval_one_epoch(epoch)\n",
    "            \n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43e89e25-1427-4de0-bf41-fcb94349cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b1()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "num_classes = 2\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "class_weights = torch.tensor([weight_class_0, weight_class_1])\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "trainer = ModelTrainer(model=model,\n",
    "                       device=device,\n",
    "                       train_dataloader=data_loader.train_loader,\n",
    "                       valid_dataloader=data_loader.test_loader,\n",
    "                       loss_fn=loss_fn,\n",
    "                       optimizer=optimizer,\n",
    "                       scheduler=scheduler,\n",
    "                       pet_type=pet_type,\n",
    "                       lesion=lesion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "397f7da3-9b44-4ecf-8c4a-43dfd0fa71e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 823/823 [06:58<00:00,  1.96batch/s]\n",
      "Epoch 2/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 3/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 4/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 5/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 6/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 7/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 8/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 9/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 10/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 11/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 12/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 13/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 14/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 15/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 16/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 17/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 18/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 19/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 20/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 21/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 22/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 23/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 24/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 25/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 26/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 27/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 28/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n",
      "Epoch 29/30: 100%|██████████| 823/823 [06:57<00:00,  1.97batch/s]\n",
      "Epoch 30/30: 100%|██████████| 823/823 [06:58<00:00,  1.97batch/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4dac2b9-a8a2-4577-8972-126d23e2a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester:\n",
    "    def __init__(self, path, device, dataloader):\n",
    "        self.device = device\n",
    "        self.dataloader = dataloader\n",
    "        self.load_model(path)\n",
    "        self.evaluate()\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = torch.load(path)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def classify(self):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(self.dataloader):\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                labels.extend(targets.cpu().numpy())\n",
    "                probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "        return predictions, labels, probabilities\n",
    "\n",
    "    def calculate_prob_stats(self, probabilities):\n",
    "        probabilities = np.array(probabilities)\n",
    "        min_probs = np.min(probabilities)\n",
    "        max_probs = np.max(probabilities)\n",
    "        std_probs = np.std(probabilities)\n",
    "        mean_probs = np.mean(probabilities)\n",
    "\n",
    "        return min_probs, max_probs, std_probs, mean_probs\n",
    "\n",
    "    def calculate_percentage(self, value):\n",
    "        return f'{value*100:.2f}%'\n",
    "\n",
    "    def evaluate(self):\n",
    "        predictions, labels, probabilities = self.classify()\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "        min_probs, max_probs, std_probs, mean_probs = self.calculate_prob_stats(probabilities)\n",
    "\n",
    "        print('Evaluation Results:')\n",
    "        print(f'Confusion Matrix:\\n{cm}')\n",
    "        print(f'Accuracy: {self.calculate_percentage(accuracy)}')\n",
    "        print(f'F1 Score: {self.calculate_percentage(f1)}')\n",
    "        print(f'Mean Probability: {self.calculate_percentage(mean_probs)}')\n",
    "        print(f'Max Probability: {self.calculate_percentage(max_probs)}')\n",
    "        print(f'Min Probability: {self.calculate_percentage(min_probs)}')\n",
    "        print(f'Standard Deviation of Probabilities: {std_probs:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62042bbe-8452-4cbb-9cbc-106474e8b741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eye/Valid/고양이/안구/일반\n",
      "eye/Valid/개/안구/일반\n",
      "Total images: 24976, Total JSON files: 24976\n",
      "Total cases: 13808\n",
      "Number of symptomatic cases: 138, Number of asymptomatic cases: 13670\n",
      "CPU times: user 749 ms, sys: 225 ms, total: 974 ms\n",
      "Wall time: 971 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'eye/Valid'\n",
    "folder_name = '일반'\n",
    "'''\n",
    "['유']\n",
    "dog: 안검염, 안검종양, 안검내반증, 유루증, 색소침착성각막염, 핵경화, 결막염\n",
    "cat: 안검염, 결막염, 각막부골편, 비궤양성각막염, 각막궤양\n",
    "['상', '하']\n",
    "dog: 궤양성각막질환, 비궤양성각막질환\n",
    "['초기', '비성숙', '성숙']\n",
    "dog: 백내장\n",
    "'''\n",
    "pet_type = '개'\n",
    "lesion = '안검염'\n",
    "devices = ['스마트폰', '일반카메라']\n",
    "symptom = ['유']\n",
    "\n",
    "processor = PathLabelProcessor(base_path=base_path,\n",
    "                                folder_name=folder_name,\n",
    "                                pet_type=pet_type,\n",
    "                                lesion=lesion,\n",
    "                                devices=devices,\n",
    "                                symptom=symptom)\n",
    "\n",
    "labeled_image_paths = processor.labeled_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6b4f548-c460-4b57-9dfd-aab096b8e5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n",
      "- Class Counts:\n",
      "  Class 1: 13670 samples\n",
      "  Class 0: 138 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432/432 [00:21<00:00, 20.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[  116    22]\n",
      " [ 1551 12119]]\n",
      "Accuracy: 88.61%\n",
      "F1 Score: 93.10%\n",
      "Mean Probability: 50.00%\n",
      "Max Probability: 99.99%\n",
      "Min Probability: 0.01%\n",
      "Standard Deviation of Probabilities: 47.87%\n",
      "CPU times: user 24.8 s, sys: 8.9 s, total: 33.8 s\n",
      "Wall time: 29.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fe352bc1300>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = ImageDataset(labeled_image_paths=labeled_image_paths,\n",
    "                       transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "path = '20231207-091641_개_안검염.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ac4fc64-78f1-4f13-a8a1-24db74dcff98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n",
      "- Class Counts:\n",
      "  Class 0: 138 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[116  22]\n",
      " [  0   0]]\n",
      "Accuracy: 84.06%\n",
      "F1 Score: 91.34%\n",
      "Mean Probability: 50.00%\n",
      "Max Probability: 99.32%\n",
      "Min Probability: 0.68%\n",
      "Standard Deviation of Probabilities: 39.77%\n",
      "CPU times: user 399 ms, sys: 3.71 s, total: 4.11 s\n",
      "Wall time: 4.14 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fe358508340>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(labeled_image_paths=[item for item in labeled_image_paths if item[1] == 0],\n",
    "                       transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbd26772-e67c-4dbc-a8e3-130455e3893e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n",
      "- Class Counts:\n",
      "  Class 1: 13670 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 428/428 [00:20<00:00, 20.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[    0     0]\n",
      " [ 1551 12119]]\n",
      "Accuracy: 88.65%\n",
      "F1 Score: 93.99%\n",
      "Mean Probability: 50.00%\n",
      "Max Probability: 99.99%\n",
      "Min Probability: 0.01%\n",
      "Standard Deviation of Probabilities: 47.94%\n",
      "CPU times: user 24.5 s, sys: 8.44 s, total: 32.9 s\n",
      "Wall time: 29.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fe3b007ed40>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(labeled_image_paths=[item for item in labeled_image_paths if item[1] == 1],\n",
    "                       transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreModelTester:\n",
    "    def __init__(self, path, device, dataloader):\n",
    "        self.device = device\n",
    "        self.dataloader = dataloader\n",
    "        self.model = models.vgg16_bn(pretrained=True)\n",
    "        self.load_model(path)\n",
    "        self.evaluate()\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = models.vgg16_bn(pretrained=True)\n",
    "        nr_filters = self.model.classifier[0].in_features\n",
    "        self.model.classifier = nn.Linear(nr_filters, 1)\n",
    "        state_dict = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "        model_dict = self.model.state_dict()\n",
    "        state_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
    "        model_dict.update(state_dict)\n",
    "        self.model.load_state_dict(model_dict)\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "    def classify(self):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(self.dataloader):\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                labels.extend(targets.cpu().numpy())\n",
    "                probabilities.extend(probs.max(dim=1).values.cpu().numpy())\n",
    "\n",
    "        return predictions, labels, probabilities\n",
    "\n",
    "    def calculate_prob_stats(self, probabilities):\n",
    "        probabilities = np.array(probabilities)\n",
    "        min_probs = np.min(probabilities)\n",
    "        max_probs = np.max(probabilities)\n",
    "        std_probs = np.std(probabilities)\n",
    "        mean_probs = np.mean(probabilities)\n",
    "\n",
    "        return min_probs, max_probs, std_probs, mean_probs\n",
    "\n",
    "    def evaluate(self):\n",
    "        predictions, labels, probabilities = self.classify()\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "        min_probs, max_probs, std_probs, mean_probs = self.calculate_prob_stats(probabilities)\n",
    "\n",
    "        print(\"Evaluation Results:\")\n",
    "        print(f\"Confusion Matrix:\\n{cm}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"Mean Probability: {mean_probs:.4f}\")\n",
    "        print(f\"Max Probability: {max_probs:.4f}\")\n",
    "        print(f\"Min Probability: {min_probs:.4f}\")        \n",
    "        print(f\"Standard Deviation of Probabilities: {std_probs:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(labeled_image_paths=labeled_image_paths,\n",
    "                       transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "path = 'pre_eye.pt'\n",
    "\n",
    "PreModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(labeled_image_paths=[item for item in labeled_image_paths if item[1] == 0],\n",
    "                       transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "PreModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(labeled_image_paths=[item for item in labeled_image_paths if item[1] == 1],\n",
    "                       transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "PreModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
