{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "115fb139-e1de-4a95-9217-2d347222f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e42b28-9d0c-449f-a4f7-48dea558eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models, transforms\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dabc5882-3298-4417-8902-fc834dc37bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathLabelProcessor:\n",
    "    def __init__(self, \n",
    "                 base_path,\n",
    "                 folder_name,\n",
    "                 pet_type,\n",
    "                 devices,\n",
    "                 symptom):\n",
    "        self.base_path = base_path\n",
    "        self.folder_name = folder_name\n",
    "        self.pet_type = pet_type\n",
    "        self.devices = devices\n",
    "        self.symptom = symptom\n",
    "        \n",
    "        self.label_images()\n",
    "      \n",
    "    def find_folders_by_name(self):\n",
    "        matching_folders = []\n",
    "\n",
    "        for root, dirs, files in os.walk(self.base_path):\n",
    "            for dir_name in dirs:\n",
    "                if self.folder_name in dir_name:\n",
    "                    folder_path = os.path.join(root, dir_name)\n",
    "                    matching_folders.append(folder_path)\n",
    "\n",
    "        for folder_path in matching_folders:\n",
    "            print(folder_path)\n",
    "            \n",
    "        return matching_folders\n",
    "\n",
    "    def find_image_json_pairs(self):\n",
    "        image_paths = []\n",
    "        json_paths = []\n",
    "\n",
    "        for folder_path in self.find_folders_by_name():\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for image_file in filter(lambda x: x.lower().endswith(('jpg', 'png')), files):\n",
    "                    image_path = os.path.join(root, image_file)\n",
    "                    json_file = f\"{os.path.splitext(image_path)[0]}.json\"\n",
    "                    if os.path.isfile(json_file):\n",
    "                        image_paths.append(image_path)\n",
    "                        json_paths.append(json_file)\n",
    "\n",
    "        print(f'Total images: {len(image_paths)}, Total JSON files: {len(json_paths)}')\n",
    "        \n",
    "        return image_paths, json_paths\n",
    "\n",
    "    def label_images(self):\n",
    "        labeled_image_paths = []\n",
    "\n",
    "        for image_path, json_path in zip(*self.find_image_json_pairs()):\n",
    "            with open(json_path) as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            if data['images']['meta']['device'] in self.devices:\n",
    "                label = 0 if data['label']['label_disease_lv_3'] in self.symptom else 1\n",
    "                labeled_image_paths.append((image_path, label))\n",
    "        \n",
    "        symptomatic_count = len(Counter(item for item in labeled_image_paths if item[1] == 0))\n",
    "        asymptomatic_count = len(Counter(item for item in labeled_image_paths if item[1] == 1))\n",
    "\n",
    "        print(f'Total cases: {len(labeled_image_paths)}')\n",
    "        print(f'Number of symptomatic cases: {symptomatic_count}, Number of asymptomatic cases: {asymptomatic_count}')\n",
    "        \n",
    "        self.labeled_image_paths = labeled_image_paths\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, labeled_image_paths, transform):\n",
    "        self.labeled_image_paths = labeled_image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labeled_image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.labeled_image_paths[idx]\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "        label = torch.tensor([label], dtype=torch.float32)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class DataLoaderMaker:\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 batch_size,\n",
    "                 train_ratio=0,\n",
    "                 num_workers=None):\n",
    "        self.dataset = dataset\n",
    "        self.train_ratio = train_ratio\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        if train_ratio:\n",
    "            self.split_and_make_dataloader()\n",
    "        else:\n",
    "            self.dataloader = self.make_dataloader(self.dataset)\n",
    "\n",
    "    def make_dataloader(self, dataset, shuffle=False):\n",
    "        dataloader = DataLoader(dataset=dataset,\n",
    "                                batch_size=self.batch_size,\n",
    "                                shuffle=shuffle,\n",
    "                                num_workers=self.num_workers,\n",
    "                                pin_memory=True)\n",
    "        \n",
    "        self.inspect_data(dataloader)\n",
    "        \n",
    "        return dataloader\n",
    "\n",
    "    def split_and_make_dataloader(self):\n",
    "        train_size = int(len(self.dataset) * self.train_ratio)\n",
    "        test_size = len(self.dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(self.dataset, [train_size, test_size])\n",
    "\n",
    "        self.train_loader = self.make_dataloader(train_dataset, shuffle=True)\n",
    "        self.test_loader = self.make_dataloader(test_dataset, shuffle=True)\n",
    "\n",
    "    def inspect_data(self, dataloader):\n",
    "        print(\"Inspecting Data...\")\n",
    "\n",
    "        class_counts = {}\n",
    "        for _, labels in dataloader:\n",
    "            labels = labels.type(torch.int)\n",
    "            for label in labels.tolist():\n",
    "                label_tuple = tuple(label)\n",
    "                class_counts[label_tuple] = class_counts.get(label_tuple, 0) + 1\n",
    "\n",
    "        print(\"- Class Counts:\")\n",
    "        for class_label, count in class_counts.items():\n",
    "            print(f\"  Class {class_label}: {count} samples\")\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 device,\n",
    "                 train_dataloader,\n",
    "                 valid_dataloader,\n",
    "                 loss_fn,\n",
    "                 optimizer,\n",
    "                 scheduler):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.best_f1_score = 0.0\n",
    "        self.start_time = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "        self.writer = SummaryWriter(log_dir=f'runs/{self.start_time}')\n",
    "\n",
    "    def calculate_f1_score(self, predicted, labels):\n",
    "        return f1_score(labels, predicted, average='binary')\n",
    "\n",
    "    def calculate_auc_roc(self, predicted, labels):\n",
    "        return roc_auc_score(labels, predicted)\n",
    "\n",
    "    def train_one_epoch(self, epoch, num_epochs):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    \n",
    "        for step, (inputs, labels) in enumerate(tqdm(self.train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "    \n",
    "            outputs = self.model(inputs)\n",
    "    \n",
    "            loss = self.loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predicted = (probs > 0.5).int()\n",
    "    \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "            loss.backward()\n",
    "    \n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "    \n",
    "        self.scheduler.step()\n",
    "        self.writer.add_scalar('LearningRate', self.scheduler.get_last_lr()[0], epoch)\n",
    "    \n",
    "        avg_loss = total_loss / len(self.train_dataloader)\n",
    "        accuracy = correct / total\n",
    "        self.writer.add_scalar('Loss/train', avg_loss, epoch)        \n",
    "        self.writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
    "\n",
    "    def eval_one_epoch(self, epoch):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_predicted = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.valid_dataloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "        \n",
    "                outputs = self.model(inputs)\n",
    "        \n",
    "                loss = self.loss_fn(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "        \n",
    "                probs = torch.sigmoid(outputs)\n",
    "                predicted = (probs > 0.5).int()\n",
    "        \n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "                all_predicted.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(self.valid_dataloader)\n",
    "        accuracy = correct / total\n",
    "        self.writer.add_scalar('Loss/valid', avg_loss, epoch)\n",
    "        self.writer.add_scalar('Accuracy/valid', accuracy, epoch)\n",
    "        \n",
    "        current_f1_score = self.calculate_f1_score(np.array(all_predicted), np.array(all_labels))\n",
    "        current_auc_roc = self.calculate_auc_roc(np.array(all_predicted), np.array(all_labels))\n",
    "        \n",
    "        self.writer.add_scalar('F1 Score/valid', current_f1_score, epoch)\n",
    "        self.writer.add_scalar('AUC-ROC/valid', current_auc_roc, epoch)\n",
    "        \n",
    "        if current_f1_score > self.best_f1_score:\n",
    "            self.best_f1_score = current_f1_score\n",
    "            torch.save(self.model.state_dict(), f'{self.start_time}.pth')\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train_one_epoch(epoch, num_epochs)\n",
    "            self.eval_one_epoch(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eye/Train/고양이/안구/일반\n",
      "eye/Train/개/안구/일반\n",
      "Total images: 199816, Total JSON files: 199816\n",
      "Total cases: 98646\n",
      "Number of symptomatic cases: 22339, Number of asymptomatic cases: 76307\n",
      "CPU times: user 6.73 s, sys: 2.34 s, total: 9.06 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'eye/Train'\n",
    "folder_name = '일반'\n",
    "pet_type = '개'\n",
    "devices = ['스마트폰', '일반카메라']\n",
    "symptom = ['유', '상', '하', '초기', '비성숙', '성숙']\n",
    "\n",
    "processor  = PathLabelProcessor(base_path=base_path,\n",
    "                                folder_name=folder_name,\n",
    "                                pet_type=pet_type,\n",
    "                                devices=devices,\n",
    "                                symptom=symptom)\n",
    "\n",
    "labeled_image_paths = processor.labeled_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "633a7dc1-1577-44e0-bec0-998cfa515e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 419 µs, sys: 0 ns, total: 419 µs\n",
      "Wall time: 430 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = ImageDataset(labeled_image_paths=labeled_image_paths,\n",
    "                       transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cbcf6b8-73fb-4a16-965b-04318cbb5cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:5\u001b[0m\n",
      "\u001b[1;32mc:\\Git\\drharu\\eye\\EyeSymptoms_Classification.ipynb Cell 6\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers \u001b[39m=\u001b[39m num_workers\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m \u001b[39mif\u001b[39;00m train_ratio:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msplit_and_make_dataloader()\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataloader(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset)\n",
      "\u001b[1;32mc:\\Git\\drharu\\eye\\EyeSymptoms_Classification.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m test_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset) \u001b[39m-\u001b[39m train_size\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m train_dataset, test_dataset \u001b[39m=\u001b[39m random_split(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, [train_size, test_size])\n\u001b[0;32m--> <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_loader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_dataloader(train_dataset, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_loader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataloader(test_dataset, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Git\\drharu\\eye\\EyeSymptoms_Classification.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_dataloader\u001b[39m(\u001b[39mself\u001b[39m, dataset, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     dataloader \u001b[39m=\u001b[39m DataLoader(dataset\u001b[39m=\u001b[39mdataset,\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m                             batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size,\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m                             shuffle\u001b[39m=\u001b[39mshuffle,\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m                             num_workers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_workers,\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m                             pin_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minspect_data(dataloader)\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m dataloader\n",
      "\u001b[1;32mc:\\Git\\drharu\\eye\\EyeSymptoms_Classification.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInspecting Data...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m class_counts \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m \u001b[39mfor\u001b[39;00m _, labels \u001b[39min\u001b[39;00m dataloader:\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m     labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mint)\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/drharu/eye/EyeSymptoms_Classification.ipynb#W5sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m     \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m labels\u001b[39m.\u001b[39mtolist():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m   1283\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[0;32m-> 1284\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1285\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1286\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[1;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[1;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 96\n",
    "num_workers = os.cpu_count()\n",
    "train_ratio = 0.8\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              train_ratio=train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2609bdf4-9610-4840-bfc5-34f85a1dfa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 171 ms, sys: 20.2 ms, total: 191 ms\n",
      "Wall time: 189 ms\n"
     ]
    }
   ],
   "source": [
    "model = models.efficientnet_b1()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, 1)\n",
    "pos_weight = torch.tensor([processor.symptomatic_count / processor.asymptomatic_count], device=device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.01)\n",
    "\n",
    "trainer = ModelTrainer(model=model,\n",
    "                       device=device,\n",
    "                       train_dataloader=data_loader.train_loader,\n",
    "                       valid_dataloader=data_loader.test_loader,\n",
    "                       loss_fn=loss_fn,\n",
    "                       optimizer=optimizer,\n",
    "                       scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b392b9d4-1711-489f-af29-19468eab8b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30:   2%|▏         | 20/823 [00:13<08:48,  1.52batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m\n",
      "\u001b[1;32mc:\\Git\\eye\\EyeSymptoms_Classification.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/eye/EyeSymptoms_Classification.ipynb#X12sZmlsZQ%3D%3D?line=221'>222</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, num_epochs):\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/eye/EyeSymptoms_Classification.ipynb#X12sZmlsZQ%3D%3D?line=222'>223</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/c%3A/Git/eye/EyeSymptoms_Classification.ipynb#X12sZmlsZQ%3D%3D?line=223'>224</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_one_epoch(epoch, num_epochs)\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/eye/EyeSymptoms_Classification.ipynb#X12sZmlsZQ%3D%3D?line=224'>225</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_one_epoch(epoch)\n",
      "\u001b[1;32mc:\\Git\\eye\\EyeSymptoms_Classification.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/eye/EyeSymptoms_Classification.ipynb#X12sZmlsZQ%3D%3D?line=164'>165</a>\u001b[0m total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/eye/EyeSymptoms_Classification.ipynb#X12sZmlsZQ%3D%3D?line=165'>166</a>\u001b[0m correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (predicted \u001b[39m==\u001b[39m labels)\u001b[39m.\u001b[39msum()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/c%3A/Git/eye/EyeSymptoms_Classification.ipynb#X12sZmlsZQ%3D%3D?line=167'>168</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/eye/EyeSymptoms_Classification.ipynb#X12sZmlsZQ%3D%3D?line=169'>170</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    <a href='vscode-notebook-cell:/c%3A/Git/eye/EyeSymptoms_Classification.ipynb#X12sZmlsZQ%3D%3D?line=170'>171</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b1cd4f3-5c00-4577-bae9-ff774b26ee88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eye/Valid/고양이/안구/일반\n",
      "eye/Valid/개/안구/일반\n",
      "Total images: 24976, Total JSON files: 24976\n",
      "Total cases: 13808\n",
      "Number of symptomatic cases: 3272, Number of asymptomatic cases: 10536\n",
      "CPU times: user 830 ms, sys: 183 ms, total: 1.01 s\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'eye/Valid'\n",
    "folder_name = '일반'\n",
    "pet_type = '개'\n",
    "devices = ['스마트폰', '일반카메라']\n",
    "symptom = ['유', '상', '하', '초기', '비성숙', '성숙']\n",
    "\n",
    "processor  = PathLabelProcessor(base_path=base_path,\n",
    "                                folder_name=folder_name,\n",
    "                                pet_type=pet_type,\n",
    "                                devices=devices,\n",
    "                                symptom=symptom)\n",
    "\n",
    "labeled_image_paths = processor.labeled_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24b8fe2d-b805-48a5-aeec-0ad909159142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 444 µs, sys: 106 µs, total: 550 µs\n",
      "Wall time: 562 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = ImageDataset(labeled_image_paths=labeled_image_paths,\n",
    "                       transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11d508cc-b873-4158-a80b-39a7e5afc8d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n",
      "- Image shape: torch.Size([3, 240, 240]), Labels: tensor([1], dtype=torch.int32)\n",
      "- Class Counts:\n",
      "  Class (1,): 32 samples\n",
      "CPU times: user 51.8 ms, sys: 335 ms, total: 387 ms\n",
      "Wall time: 831 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 32\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              train_ratio=train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0902981d-8b7e-4a4c-b707-3d8fa550bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester:\n",
    "    def __init__(self, path, model, device, dataloader):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.dataloader = dataloader\n",
    "        self.load_weights(path)\n",
    "        self.evaluate()\n",
    "\n",
    "    def load_weights(self, path):\n",
    "        weights = torch.load(path)\n",
    "        self.model.load_state_dict(weights)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def classify(self):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        pos_probabilities = []\n",
    "        neg_probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(self.dataloader):\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                labels.extend(targets.cpu().numpy())\n",
    "                pos_probabilities.extend(probs[:, 0].cpu().numpy())\n",
    "                neg_probabilities.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "        return predictions, labels, pos_probabilities, neg_probabilities\n",
    "\n",
    "    def calculate_prob_stats(self, probabilities):\n",
    "        probabilities = np.array(probabilities)\n",
    "        min_probs = np.min(probabilities, axis=0)\n",
    "        max_probs = np.max(probabilities, axis=0)\n",
    "        std_probs = np.std(probabilities, axis=0)\n",
    "\n",
    "        return min_probs, max_probs, std_probs\n",
    "\n",
    "    def evaluate(self):\n",
    "        predictions, labels, pos_probabilities, neg_probabilities = self.classify()\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        precision = precision_score(labels, predictions)\n",
    "        recall = recall_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions)\n",
    "\n",
    "        pos_min_probs, pos_max_probs, pos_std_probs = self.calculate_prob_stats(pos_probabilities)\n",
    "        neg_min_probs, neg_max_probs, neg_std_probs = self.calculate_prob_stats(neg_probabilities)\n",
    "\n",
    "        print(\"Evaluation Results:\")\n",
    "        print(f\"Confusion Matrix:\\n{cm}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"Min Probabilities of positive: {pos_min_probs}\")\n",
    "        print(f\"Max Probabilities of positive: {pos_max_probs}\")\n",
    "        print(f\"Standard Deviation of Probabilities of positive: {pos_std_probs}\")\n",
    "        print(f\"Min Probabilities of negative: {neg_min_probs}\")\n",
    "        print(f\"Max Probabilities of negative: {neg_max_probs}\")\n",
    "        print(f\"Standard Deviation of Probabilities of negative: {neg_std_probs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c9e02-67d0-4b7b-848e-b77bd5f68339",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '20231123-033657.pth'\n",
    "model = models.efficientnet_b1()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = 2\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "ModelTester(path=path, model=model, device=device, dataloader=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7857ec-724e-4b1c-a39d-7ed155fa4f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier:\n",
    "    def __init__(self, device, image_path, image_transform, model_weights_path, model):\n",
    "        self.image_path = image_path\n",
    "        self.image_transform = image_transform\n",
    "        self.device = device\n",
    "        self.model = model\n",
    "        self.load_model_weights(model_weights_path)\n",
    "\n",
    "    def preprocess_image(self):\n",
    "        image = Image.open(self.image_path)\n",
    "        input_data = self.image_transform(image).unsqueeze(0)\n",
    "        input_data = input_data.to(self.device)\n",
    "        return input_data\n",
    "\n",
    "    def load_model_weights(self, weights_path):\n",
    "        weights = torch.load(weights_path)\n",
    "        self.model.load_state_dict(weights)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def classify_image(self):\n",
    "        self.model.eval()\n",
    "        input_data = self.preprocess_image()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model(input_data)\n",
    "        \n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "        predicted_prob, predicted_class = torch.max(probabilities, 1)\n",
    "        \n",
    "        class_label = \"Disease\" if predicted_class.item() == 0 else \"Normal\"\n",
    "        class_prob = probabilities[0, predicted_class].item() * 100\n",
    "\n",
    "        print(f\"The image is predicted to be {class_label} with {class_prob:.2f}% probability.\")\n",
    "                \n",
    "        return predicted_class.item(), class_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf2ca04-852d-47e0-8d69-699754938886",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "image_path = 'kIHjZsKQ6HdQ.jpg'\n",
    "image_transform = transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "model_weights_path = 'best_model.pth'\n",
    "model = models.efficientnet_b1()\n",
    "num_classes = 2\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "classifier = ImageClassifier(device=device,\n",
    "                             image_path=image_path,\n",
    "                             image_transform=image_transform,\n",
    "                             model_weights_path=model_weights_path,\n",
    "                             model=model)\n",
    "\n",
    "predicted_class = classifier.classify_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febe786e-2ee5-4f65-a943-ebdd99ea6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from your_dataset_module import CustomDataset\n",
    "from your_trainer_module import ModelTrainer\n",
    "\n",
    "def train_tune(config):\n",
    "    # Define your model and other components\n",
    "    model = models.efficientnet_b1()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(num_ftrs, 1)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.01)\n",
    "    \n",
    "    trainer = ModelTrainer(model=model,\n",
    "                           device=device,\n",
    "                           train_dataloader=train_dataloader,\n",
    "                           valid_dataloader=valid_dataloader,\n",
    "                           loss_fn=loss_fn,\n",
    "                           optimizer=optimizer,\n",
    "                           scheduler=scheduler)\n",
    "    \n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        trainer.train_one_epoch(epoch, num_epochs)\n",
    "        trainer.eval_one_epoch(epoch)\n",
    "\n",
    "    return trainer.best_f1_score\n",
    "\n",
    "search_space = {\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "    \"weight_decay\": tune.loguniform(1e-6, 1e-2),\n",
    "    \"step_size\": tune.choice([3, 5, 7]),\n",
    "    \"gamma\": tune.choice([0.01, 0.1, 0.5]),\n",
    "}\n",
    "\n",
    "scheduler = ASHAScheduler(max_t=10, grace_period=1)\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_tune,\n",
    "    config=search_space,\n",
    "    num_samples=10,\n",
    "    scheduler=scheduler,\n",
    "    metric=\"f1_score\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "\n",
    "best_hyperparameters = analysis.get_best_config(metric=\"f1_score\", mode=\"max\")\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95829139-666d-4ef2-bd37-fc62f96d3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    " \n",
    "# ### homomorphic filter는 gray scale image에 대해서 밖에 안 되므로\n",
    "# ### YUV color space로 converting한 뒤 Y에 대해 연산을 진행\n",
    "# img = cv2.imread('file path')\n",
    "# img_YUV = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)    \n",
    "# y = img_YUV[::0]    \n",
    " \n",
    "# rows = y.shape[0]    \n",
    "# cols = y.shape[1]\n",
    " \n",
    "# ### illumination elements와 reflectance elements를 분리하기 위해 log를 취함\n",
    "# imgLog = np.log1p(np.array(y, dtype='float') / 255) # y값을 0~1사이로 조정한 뒤 log(x+1)\n",
    " \n",
    "# ### frequency를 이미지로 나타내면 4분면에 대칭적으로 나타나므로 \n",
    "# ### 4분면 중 하나에 이미지를 대응시키기 위해 row와 column을 2배씩 늘려줌\n",
    "# M = 2*rows + 1\n",
    "# N = 2*cols + 1\n",
    " \n",
    "# ### gaussian mask 생성 sigma = 10\n",
    "# sigma = 10\n",
    "# (X, Y) = np.meshgrid(np.linspace(0, N-1, N), np.linspace(0, M-1, M)) # 0~N-1(and M-1) 까지 1단위로 space를 만듬\n",
    "# Xc = np.ceil(N/2) # 올림 연산\n",
    "# Yc = np.ceil(M/2)\n",
    "# gaussianNumerator = (X - Xc)**2 + (Y - Yc)**2 # 가우시안 분자 생성\n",
    " \n",
    "# ### low pass filter와 high pass filter 생성\n",
    "# LPF = np.exp(-gaussianNumerator / (2*sigma*sigma))\n",
    "# HPF = 1 - LPF\n",
    " \n",
    "# ### LPF랑 HPF를 0이 가운데로 오도록iFFT함. \n",
    "# ### 사실 이 부분이 잘 이해가 안 가는데 plt로 이미지를 띄워보니 shuffling을 수행한 효과가 났음\n",
    "# ### 에너지를 각 귀퉁이로 모아 줌\n",
    "# LPF_shift = np.fft.ifftshift(LPF.copy())\n",
    "# HPF_shift = np.fft.ifftshift(HPF.copy())\n",
    " \n",
    "# ### Log를 씌운 이미지를 FFT해서 LPF와 HPF를 곱해 LF성분과 HF성분을 나눔\n",
    "# img_FFT = np.fft.fft2(imgLog.copy(), (M, N))\n",
    "# img_LF = np.real(np.fft.ifft2(img_FFT.copy() * LPF_shift, (M, N)) # low frequency 성분\n",
    "# img_HF = np.real(np.fft.ifft2(img_FFT.copy() * HPF_shift, (M, N)) # high frequency 성분\n",
    " \n",
    "# ### 각 LF, HF 성분에 scaling factor를 곱해주어 조명값과 반사값을 조절함\n",
    "# gamma1 = 0.3\n",
    "# gamma2 = 1.5\n",
    "# img_adjusting = gamma1*img_LF[0:rows, 0:cols] + gamma2*img_HF[0:rows, 0:cols]\n",
    " \n",
    "# ### 조정된 데이터를 이제 exp 연산을 통해 이미지로 만들어줌\n",
    "# img_exp = np.expm1(img_adjusting) # exp(x) + 1\n",
    "# img_exp = (img_exp - np.min(img_exp)) / (np.max(img_exp) - np.min(img_exp)) # 0~1사이로 정규화\n",
    "# img_out = np.array(255*img_exp, dtype = 'uint8') # 255를 곱해서 intensity값을 만들어줌\n",
    " \n",
    "# ### 마지막으로 YUV에서 Y space를 filtering된 이미지로 교체해주고 RGB space로 converting\n",
    "# img_YUV[:,:,0] = img_out\n",
    "# result = cv2.cvtColor(img_YUV, cv2.COLOR_YUV2BGR)\n",
    "# cv2.imshow('homomorphic', result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
