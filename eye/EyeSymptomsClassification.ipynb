{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "115fb139-e1de-4a95-9217-2d347222f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e42b28-9d0c-449f-a4f7-48dea558eefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models, transforms\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dabc5882-3298-4417-8902-fc834dc37bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathLabelProcessor:\n",
    "    def __init__(self, \n",
    "                 base_path,\n",
    "                 folder_name,\n",
    "                 devices,\n",
    "                 symptom):\n",
    "        self.base_path = base_path\n",
    "        self.folder_name = folder_name\n",
    "        self.devices = devices\n",
    "        self.symptom = symptom\n",
    "        \n",
    "        self.label_images()\n",
    "      \n",
    "    def find_folders_by_name(self):\n",
    "        matching_folders = []\n",
    "\n",
    "        for root, dirs, files in os.walk(self.base_path):\n",
    "            for dir_name in dirs:\n",
    "                if self.folder_name in dir_name:\n",
    "                    folder_path = os.path.join(root, dir_name)\n",
    "                    matching_folders.append(folder_path)\n",
    "\n",
    "        for folder_path in matching_folders:\n",
    "            print(folder_path)\n",
    "            \n",
    "        return matching_folders\n",
    "\n",
    "    def find_image_json_pairs(self):\n",
    "        image_paths = []\n",
    "        json_paths = []\n",
    "\n",
    "        for folder_path in self.find_folders_by_name():\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for image_file in filter(lambda x: x.lower().endswith(('jpg', 'png')), files):\n",
    "                    image_path = os.path.join(root, image_file)\n",
    "                    json_file = f\"{os.path.splitext(image_path)[0]}.json\"\n",
    "                    if os.path.isfile(json_file):\n",
    "                        image_paths.append(image_path)\n",
    "                        json_paths.append(json_file)\n",
    "\n",
    "        print(f'Total images: {len(image_paths)}, Total JSON files: {len(json_paths)}')\n",
    "        \n",
    "        return image_paths, json_paths\n",
    "\n",
    "    def label_images(self):\n",
    "        self.labeled_image_paths = []\n",
    "\n",
    "        for image_path, json_path in zip(*self.find_image_json_pairs()):\n",
    "            with open(json_path) as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            if data['images']['meta']['device'] in self.devices:\n",
    "                label = 0 if data['label']['label_disease_lv_3'] in self.symptom else 1\n",
    "                self.labeled_image_paths.append((image_path, label))\n",
    "        \n",
    "        self.symptomatic_count = len(Counter(item for item in self.labeled_image_paths if item[1] == 0))\n",
    "        self.asymptomatic_count = len(Counter(item for item in self.labeled_image_paths if item[1] == 1))\n",
    "\n",
    "        print(f'Total cases: {len(self.labeled_image_paths)}')\n",
    "        print(f'Number of symptomatic cases: {self.symptomatic_count}, Number of asymptomatic cases: {self.asymptomatic_count}')\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, labeled_image_paths, transform):\n",
    "        self.labeled_image_paths = labeled_image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labeled_image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.labeled_image_paths[idx]\n",
    "\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class DataLoaderMaker:\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 batch_size,\n",
    "                 train_ratio=0,\n",
    "                 num_workers=None):\n",
    "        self.dataset = dataset\n",
    "        self.train_ratio = train_ratio\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        if train_ratio:\n",
    "            self.split_and_make_dataloader()\n",
    "        else:\n",
    "            self.dataloader = self.make_dataloader(self.dataset)\n",
    "\n",
    "    def make_dataloader(self, dataset, shuffle=False):\n",
    "        dataloader = DataLoader(dataset=dataset,\n",
    "                                batch_size=self.batch_size,\n",
    "                                shuffle=shuffle,\n",
    "                                num_workers=self.num_workers,\n",
    "                                pin_memory=True)\n",
    "        \n",
    "        self.inspect_data(dataloader)\n",
    "        \n",
    "        return dataloader\n",
    "\n",
    "    def split_and_make_dataloader(self):\n",
    "        train_size = int(len(self.dataset) * self.train_ratio)\n",
    "        test_size = len(self.dataset) - train_size\n",
    "        train_dataset, test_dataset = random_split(self.dataset, [train_size, test_size])\n",
    "\n",
    "        self.train_loader = self.make_dataloader(train_dataset, shuffle=True)\n",
    "        self.test_loader = self.make_dataloader(test_dataset, shuffle=True)\n",
    "\n",
    "    def inspect_data(self, dataloader):\n",
    "        print(\"Inspecting Data...\")\n",
    "\n",
    "        class_counts = {}\n",
    "        for _, labels in dataloader:\n",
    "            for label in labels.tolist():\n",
    "                class_counts[label] = class_counts.get(label, 0) + 1\n",
    "\n",
    "        print(\"- Class Counts:\")\n",
    "        for class_label, count in class_counts.items():\n",
    "            print(f\"  Class {class_label}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eye/Train/고양이/안구/일반\n",
      "eye/Train/개/안구/일반\n",
      "Total images: 199816, Total JSON files: 199816\n",
      "Total cases: 98646\n",
      "Number of symptomatic cases: 22339, Number of asymptomatic cases: 76307\n",
      "CPU times: user 6.67 s, sys: 1.86 s, total: 8.53 s\n",
      "Wall time: 8.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'eye/Train'\n",
    "folder_name = '일반'\n",
    "devices = ['스마트폰', '일반카메라']\n",
    "symptom = ['유', '상', '하', '초기', '비성숙', '성숙']\n",
    "\n",
    "processor = PathLabelProcessor(base_path=base_path,\n",
    "                                folder_name=folder_name,\n",
    "                                devices=devices,\n",
    "                                symptom=symptom)\n",
    "\n",
    "labeled_image_paths = processor.labeled_image_paths\n",
    "weight_class_0 = 1.0 / processor.symptomatic_count\n",
    "weight_class_1 = 1.0 / processor.asymptomatic_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "633a7dc1-1577-44e0-bec0-998cfa515e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 176 µs, sys: 64 µs, total: 240 µs\n",
      "Wall time: 246 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = ImageDataset(labeled_image_paths=labeled_image_paths,\n",
    "                       transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cbcf6b8-73fb-4a16-965b-04318cbb5cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n",
      "- Class Counts:\n",
      "  Class 1: 61080 samples\n",
      "  Class 0: 17836 samples\n",
      "Inspecting Data...\n",
      "- Class Counts:\n",
      "  Class 1: 15227 samples\n",
      "  Class 0: 4503 samples\n",
      "CPU times: user 23.7 s, sys: 22.5 s, total: 46.2 s\n",
      "Wall time: 55.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size = 96\n",
    "num_workers = os.cpu_count()\n",
    "train_ratio = 0.8\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              train_ratio=train_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 device,\n",
    "                 train_dataloader,\n",
    "                 valid_dataloader,\n",
    "                 loss_fn,\n",
    "                 optimizer,\n",
    "                 scheduler):\n",
    "        self.device = device\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.loss_fn = loss_fn.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.best_f1_score = 0.0\n",
    "        korea = pytz.timezone('Asia/Seoul')\n",
    "        now = datetime.now(korea)\n",
    "        start_time = now.strftime('%Y%m%d-%H%M%S')\n",
    "        self.name = f'{start_time}_symptoms.pth'\n",
    "        self.writer = SummaryWriter(log_dir=f'runs/{self.name}')\n",
    "\n",
    "    def calculate_f1_score(self, predicted, labels):\n",
    "        return f1_score(labels, predicted, average='binary')\n",
    "\n",
    "    def calculate_auc_roc(self, predicted, labels):\n",
    "        return roc_auc_score(labels, predicted)\n",
    "\n",
    "    def train_one_epoch(self, epoch, num_epochs):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "    \n",
    "        for step, (inputs, labels) in enumerate(tqdm(self.train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "    \n",
    "            outputs = self.model(inputs)\n",
    "            \n",
    "            loss = self.loss_fn(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "            loss.backward()\n",
    "    \n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "    \n",
    "        self.scheduler.step()\n",
    "        self.writer.add_scalar('LearningRate', self.scheduler.get_last_lr()[0], epoch)\n",
    "    \n",
    "        avg_loss = total_loss / len(self.train_dataloader)\n",
    "        accuracy = correct / total\n",
    "        self.writer.add_scalar('Loss/train', avg_loss, epoch)        \n",
    "        self.writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
    "\n",
    "    def eval_one_epoch(self, epoch):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_predicted = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in self.valid_dataloader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "        \n",
    "                outputs = self.model(inputs)\n",
    "        \n",
    "                loss = self.loss_fn(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "        \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "                all_predicted.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_loss = total_loss / len(self.valid_dataloader)\n",
    "        accuracy = correct / total\n",
    "        self.writer.add_scalar('Loss/valid', avg_loss, epoch)\n",
    "        self.writer.add_scalar('Accuracy/valid', accuracy, epoch)\n",
    "        \n",
    "        current_f1_score = self.calculate_f1_score(np.array(all_predicted), np.array(all_labels))\n",
    "        current_auc_roc = self.calculate_auc_roc(np.array(all_predicted), np.array(all_labels))\n",
    "        \n",
    "        self.writer.add_scalar('F1 Score/valid', current_f1_score, epoch)\n",
    "        self.writer.add_scalar('AUC-ROC/valid', current_auc_roc, epoch)\n",
    "        \n",
    "        if current_f1_score > self.best_f1_score:\n",
    "            self.best_f1_score = current_f1_score\n",
    "            torch.save(self.model, self.name)\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train_one_epoch(epoch, num_epochs)\n",
    "            self.eval_one_epoch(epoch)\n",
    "            \n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2609bdf4-9610-4840-bfc5-34f85a1dfa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.efficientnet_b1()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "num_classes = 2\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "class_weights = torch.tensor([weight_class_0, weight_class_1])\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "trainer = ModelTrainer(model=model,\n",
    "                       device=device,\n",
    "                       train_dataloader=data_loader.train_loader,\n",
    "                       valid_dataloader=data_loader.test_loader,\n",
    "                       loss_fn=loss_fn,\n",
    "                       optimizer=optimizer,\n",
    "                       scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b392b9d4-1711-489f-af29-19468eab8b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 823/823 [06:59<00:00,  1.96batch/s]\n",
      "Epoch 2/30:   1%|          | 8/823 [00:05<07:16,  1.87batch/s]"
     ]
    }
   ],
   "source": [
    "trainer.train(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0902981d-8b7e-4a4c-b707-3d8fa550bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTester:\n",
    "    def __init__(self, path, device, dataloader):\n",
    "        self.device = device\n",
    "        self.dataloader = dataloader\n",
    "        self.load_model(path)\n",
    "        self.evaluate()\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = torch.load(path)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def classify(self):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(self.dataloader):\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                labels.extend(targets.cpu().numpy())\n",
    "                probabilities.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "        return predictions, labels, probabilities\n",
    "\n",
    "    def calculate_prob_stats(self, probabilities):\n",
    "        probabilities = np.array(probabilities)\n",
    "        min_probs = np.min(probabilities)\n",
    "        max_probs = np.max(probabilities)\n",
    "        std_probs = np.std(probabilities)\n",
    "        mean_probs = np.mean(probabilities)\n",
    "\n",
    "        return min_probs, max_probs, std_probs, mean_probs\n",
    "\n",
    "    def evaluate(self):\n",
    "        predictions, labels, probabilities = self.classify()\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        precision = precision_score(labels, predictions, average='weighted')\n",
    "        recall = recall_score(labels, predictions, average='weighted')\n",
    "        f1 = f1_score(labels, predictions, average='weighted')\n",
    "\n",
    "        min_probs, max_probs, std_probs, mean_probs = self.calculate_prob_stats(probabilities)\n",
    "\n",
    "        print(\"Evaluation Results:\")\n",
    "        print(f\"Confusion Matrix:\\n{cm}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"Min Probability: {min_probs:.4f}\")\n",
    "        print(f\"Max Probability: {max_probs:.4f}\")\n",
    "        print(f\"Standard Deviation of Probabilities: {std_probs:.4f}\")\n",
    "        print(f\"Mean Probability: {mean_probs:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b1cd4f3-5c00-4577-bae9-ff774b26ee88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eye/Valid/고양이/안구/일반\n",
      "eye/Valid/개/안구/일반\n",
      "Total images: 24976, Total JSON files: 24976\n",
      "Total cases: 13808\n",
      "Number of symptomatic cases: 3272, Number of asymptomatic cases: 10536\n",
      "CPU times: user 829 ms, sys: 218 ms, total: 1.05 s\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_path = 'eye/Valid'\n",
    "folder_name = '일반'\n",
    "devices = ['스마트폰', '일반카메라']\n",
    "symptom = ['유', '상', '하', '초기', '비성숙', '성숙']\n",
    "\n",
    "processor = PathLabelProcessor(base_path=base_path,\n",
    "                                folder_name=folder_name,\n",
    "                                devices=devices,\n",
    "                                symptom=symptom)\n",
    "\n",
    "labeled_image_paths = processor.labeled_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b8fe2d-b805-48a5-aeec-0ad909159142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n",
      "- Class Counts:\n",
      "  Class (1,): 10536 samples\n",
      "  Class (0,): 3272 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 432/432 [00:42<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[ 3272     0]\n",
      " [10536     0]]\n",
      "Accuracy: 0.2370\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Min Probability: 1.0000\n",
      "Max Probability: 1.0000\n",
      "Standard Deviation of Probabilities: 0.0000\n",
      "Mean Probability: 1.0000\n",
      "CPU times: user 49.7 s, sys: 6.46 s, total: 56.1 s\n",
      "Wall time: 53.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fa683e5e350>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "transform = transforms.Compose([transforms.Resize((240, 240)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = ImageDataset(labeled_image_paths=labeled_image_paths,\n",
    "                       transform=transform)\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "path = '20231204-200922_symptoms.pth'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Class Counts:\n",
      "  Class (0,): 3272 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:10<00:00,  9.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[3272]]\n",
      "Accuracy: 1.0000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Min Probability: 1.0000\n",
      "Max Probability: 1.0000\n",
      "Standard Deviation of Probabilities: 0.0000\n",
      "Mean Probability: 1.0000\n",
      "CPU times: user 12.6 s, sys: 2.13 s, total: 14.8 s\n",
      "Wall time: 14.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fa68389efb0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(labeled_image_paths=[item for item in labeled_image_paths if item[1] == 0],\n",
    "                       transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Class Counts:\n",
      "  Class (1,): 10536 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330/330 [00:32<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[    0     0]\n",
      " [10536     0]]\n",
      "Accuracy: 0.0000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Min Probability: 1.0000\n",
      "Max Probability: 1.0000\n",
      "Standard Deviation of Probabilities: 0.0000\n",
      "Mean Probability: 1.0000\n",
      "CPU times: user 38 s, sys: 4.9 s, total: 42.9 s\n",
      "Wall time: 41.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7fa7df2fcd90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(labeled_image_paths=[item for item in labeled_image_paths if item[1] == 1],\n",
    "                       transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "ModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreModelTester:\n",
    "    def __init__(self, path, device, dataloader):\n",
    "        self.device = device\n",
    "        self.dataloader = dataloader\n",
    "        self.model = models.vgg16_bn(pretrained=True)\n",
    "        self.load_model(path)\n",
    "        self.evaluate()\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.model = models.vgg16_bn(pretrained=True)\n",
    "        nr_filters = self.model.classifier[0].in_features\n",
    "        self.model.classifier = nn.Linear(nr_filters, 1)\n",
    "        state_dict = torch.load(path, map_location=torch.device(\"cpu\"))\n",
    "        model_dict = self.model.state_dict()\n",
    "        state_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
    "        model_dict.update(state_dict)\n",
    "        self.model.load_state_dict(model_dict)\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "    def classify(self):\n",
    "        self.model.eval()\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        probabilities = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in tqdm(self.dataloader):\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                \n",
    "                logits = torch.nn.functional.sigmoid(outputs)\n",
    "                predicted = (logits > 0.5).int()\n",
    "\n",
    "                predictions.extend(predicted.cpu().numpy())\n",
    "                labels.extend(targets.cpu().numpy())\n",
    "                probabilities.extend(logits.cpu().numpy())\n",
    "\n",
    "        return predictions, labels, probabilities\n",
    "\n",
    "    def calculate_prob_stats(self, probabilities):\n",
    "        probabilities = np.array(probabilities)\n",
    "        min_probs = np.min(probabilities)\n",
    "        max_probs = np.max(probabilities)\n",
    "        std_probs = np.std(probabilities)\n",
    "        mean_probs = np.mean(probabilities)\n",
    "\n",
    "        return min_probs, max_probs, std_probs, mean_probs\n",
    "\n",
    "    def evaluate(self):\n",
    "        predictions, labels, probabilities = self.classify()\n",
    "        cm = confusion_matrix(labels, predictions)\n",
    "        accuracy = accuracy_score(labels, predictions)\n",
    "        precision = precision_score(labels, predictions)\n",
    "        recall = recall_score(labels, predictions)\n",
    "        f1 = f1_score(labels, predictions)\n",
    "\n",
    "        min_probs, max_probs, std_probs, mean_probs = self.calculate_prob_stats(probabilities)\n",
    "\n",
    "        print(\"Evaluation Results:\")\n",
    "        print(f\"Confusion Matrix:\\n{cm}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "        print(f\"Min Probability: {min_probs:.4f}\")\n",
    "        print(f\"Max Probability: {max_probs:.4f}\")\n",
    "        print(f\"Standard Deviation of Probabilities: {std_probs:.4f}\")\n",
    "        print(f\"Mean Probability: {mean_probs:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Class Counts:\n",
      "  Class (0,): 22339 samples\n",
      "  Class (1,): 76307 samples\n",
      "Loaded Model Information:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 240, 240]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 240, 240]             128\n",
      "              ReLU-3         [-1, 64, 240, 240]               0\n",
      "            Conv2d-4         [-1, 64, 240, 240]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 240, 240]             128\n",
      "              ReLU-6         [-1, 64, 240, 240]               0\n",
      "         MaxPool2d-7         [-1, 64, 120, 120]               0\n",
      "            Conv2d-8        [-1, 128, 120, 120]          73,856\n",
      "       BatchNorm2d-9        [-1, 128, 120, 120]             256\n",
      "             ReLU-10        [-1, 128, 120, 120]               0\n",
      "           Conv2d-11        [-1, 128, 120, 120]         147,584\n",
      "      BatchNorm2d-12        [-1, 128, 120, 120]             256\n",
      "             ReLU-13        [-1, 128, 120, 120]               0\n",
      "        MaxPool2d-14          [-1, 128, 60, 60]               0\n",
      "           Conv2d-15          [-1, 256, 60, 60]         295,168\n",
      "      BatchNorm2d-16          [-1, 256, 60, 60]             512\n",
      "             ReLU-17          [-1, 256, 60, 60]               0\n",
      "           Conv2d-18          [-1, 256, 60, 60]         590,080\n",
      "      BatchNorm2d-19          [-1, 256, 60, 60]             512\n",
      "             ReLU-20          [-1, 256, 60, 60]               0\n",
      "           Conv2d-21          [-1, 256, 60, 60]         590,080\n",
      "      BatchNorm2d-22          [-1, 256, 60, 60]             512\n",
      "             ReLU-23          [-1, 256, 60, 60]               0\n",
      "        MaxPool2d-24          [-1, 256, 30, 30]               0\n",
      "           Conv2d-25          [-1, 512, 30, 30]       1,180,160\n",
      "      BatchNorm2d-26          [-1, 512, 30, 30]           1,024\n",
      "             ReLU-27          [-1, 512, 30, 30]               0\n",
      "           Conv2d-28          [-1, 512, 30, 30]       2,359,808\n",
      "      BatchNorm2d-29          [-1, 512, 30, 30]           1,024\n",
      "             ReLU-30          [-1, 512, 30, 30]               0\n",
      "           Conv2d-31          [-1, 512, 30, 30]       2,359,808\n",
      "      BatchNorm2d-32          [-1, 512, 30, 30]           1,024\n",
      "             ReLU-33          [-1, 512, 30, 30]               0\n",
      "        MaxPool2d-34          [-1, 512, 15, 15]               0\n",
      "           Conv2d-35          [-1, 512, 15, 15]       2,359,808\n",
      "      BatchNorm2d-36          [-1, 512, 15, 15]           1,024\n",
      "             ReLU-37          [-1, 512, 15, 15]               0\n",
      "           Conv2d-38          [-1, 512, 15, 15]       2,359,808\n",
      "      BatchNorm2d-39          [-1, 512, 15, 15]           1,024\n",
      "             ReLU-40          [-1, 512, 15, 15]               0\n",
      "           Conv2d-41          [-1, 512, 15, 15]       2,359,808\n",
      "      BatchNorm2d-42          [-1, 512, 15, 15]           1,024\n",
      "             ReLU-43          [-1, 512, 15, 15]               0\n",
      "        MaxPool2d-44            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-45            [-1, 512, 7, 7]               0\n",
      "           Linear-46                    [-1, 1]          25,089\n",
      "================================================================\n",
      "Total params: 14,748,225\n",
      "Trainable params: 14,748,225\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.66\n",
      "Forward/backward pass size (MB): 369.52\n",
      "Params size (MB): 56.26\n",
      "Estimated Total Size (MB): 426.44\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1028/1028 [04:45<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[22339     0]\n",
      " [76307     0]]\n",
      "Accuracy: 0.2265\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Min Probability: 1.0000\n",
      "Max Probability: 1.0000\n",
      "Standard Deviation of Probabilities: 0.0000\n",
      "Mean Probability: 1.0000\n",
      "CPU times: user 5min 25s, sys: 34.2 s, total: 5min 59s\n",
      "Wall time: 5min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7f24d0ace1a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(labeled_image_paths=labeled_image_paths,\n",
    "                       transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "path = 'pre_eye.pt'\n",
    "\n",
    "PreModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n",
      "- Class Counts:\n",
      "  Class (0,): 22339 samples\n",
      "Loaded Model Information:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 240, 240]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 240, 240]             128\n",
      "              ReLU-3         [-1, 64, 240, 240]               0\n",
      "            Conv2d-4         [-1, 64, 240, 240]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 240, 240]             128\n",
      "              ReLU-6         [-1, 64, 240, 240]               0\n",
      "         MaxPool2d-7         [-1, 64, 120, 120]               0\n",
      "            Conv2d-8        [-1, 128, 120, 120]          73,856\n",
      "       BatchNorm2d-9        [-1, 128, 120, 120]             256\n",
      "             ReLU-10        [-1, 128, 120, 120]               0\n",
      "           Conv2d-11        [-1, 128, 120, 120]         147,584\n",
      "      BatchNorm2d-12        [-1, 128, 120, 120]             256\n",
      "             ReLU-13        [-1, 128, 120, 120]               0\n",
      "        MaxPool2d-14          [-1, 128, 60, 60]               0\n",
      "           Conv2d-15          [-1, 256, 60, 60]         295,168\n",
      "      BatchNorm2d-16          [-1, 256, 60, 60]             512\n",
      "             ReLU-17          [-1, 256, 60, 60]               0\n",
      "           Conv2d-18          [-1, 256, 60, 60]         590,080\n",
      "      BatchNorm2d-19          [-1, 256, 60, 60]             512\n",
      "             ReLU-20          [-1, 256, 60, 60]               0\n",
      "           Conv2d-21          [-1, 256, 60, 60]         590,080\n",
      "      BatchNorm2d-22          [-1, 256, 60, 60]             512\n",
      "             ReLU-23          [-1, 256, 60, 60]               0\n",
      "        MaxPool2d-24          [-1, 256, 30, 30]               0\n",
      "           Conv2d-25          [-1, 512, 30, 30]       1,180,160\n",
      "      BatchNorm2d-26          [-1, 512, 30, 30]           1,024\n",
      "             ReLU-27          [-1, 512, 30, 30]               0\n",
      "           Conv2d-28          [-1, 512, 30, 30]       2,359,808\n",
      "      BatchNorm2d-29          [-1, 512, 30, 30]           1,024\n",
      "             ReLU-30          [-1, 512, 30, 30]               0\n",
      "           Conv2d-31          [-1, 512, 30, 30]       2,359,808\n",
      "      BatchNorm2d-32          [-1, 512, 30, 30]           1,024\n",
      "             ReLU-33          [-1, 512, 30, 30]               0\n",
      "        MaxPool2d-34          [-1, 512, 15, 15]               0\n",
      "           Conv2d-35          [-1, 512, 15, 15]       2,359,808\n",
      "      BatchNorm2d-36          [-1, 512, 15, 15]           1,024\n",
      "             ReLU-37          [-1, 512, 15, 15]               0\n",
      "           Conv2d-38          [-1, 512, 15, 15]       2,359,808\n",
      "      BatchNorm2d-39          [-1, 512, 15, 15]           1,024\n",
      "             ReLU-40          [-1, 512, 15, 15]               0\n",
      "           Conv2d-41          [-1, 512, 15, 15]       2,359,808\n",
      "      BatchNorm2d-42          [-1, 512, 15, 15]           1,024\n",
      "             ReLU-43          [-1, 512, 15, 15]               0\n",
      "        MaxPool2d-44            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-45            [-1, 512, 7, 7]               0\n",
      "           Linear-46                    [-1, 1]          25,089\n",
      "================================================================\n",
      "Total params: 14,748,225\n",
      "Trainable params: 14,748,225\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.66\n",
      "Forward/backward pass size (MB): 369.52\n",
      "Params size (MB): 56.26\n",
      "Estimated Total Size (MB): 426.44\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 233/233 [01:06<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[22339]]\n",
      "Accuracy: 1.0000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Min Probability: 1.0000\n",
      "Max Probability: 1.0000\n",
      "Standard Deviation of Probabilities: 0.0000\n",
      "Mean Probability: 1.0000\n",
      "CPU times: user 1min 17s, sys: 11.5 s, total: 1min 28s\n",
      "Wall time: 1min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7f24d0acda80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(labeled_image_paths=[item for item in labeled_image_paths if item[1] == 0],\n",
    "                       transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "PreModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Data...\n",
      "- Class Counts:\n",
      "  Class (1,): 76307 samples\n",
      "Loaded Model Information:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 240, 240]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 240, 240]             128\n",
      "              ReLU-3         [-1, 64, 240, 240]               0\n",
      "            Conv2d-4         [-1, 64, 240, 240]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 240, 240]             128\n",
      "              ReLU-6         [-1, 64, 240, 240]               0\n",
      "         MaxPool2d-7         [-1, 64, 120, 120]               0\n",
      "            Conv2d-8        [-1, 128, 120, 120]          73,856\n",
      "       BatchNorm2d-9        [-1, 128, 120, 120]             256\n",
      "             ReLU-10        [-1, 128, 120, 120]               0\n",
      "           Conv2d-11        [-1, 128, 120, 120]         147,584\n",
      "      BatchNorm2d-12        [-1, 128, 120, 120]             256\n",
      "             ReLU-13        [-1, 128, 120, 120]               0\n",
      "        MaxPool2d-14          [-1, 128, 60, 60]               0\n",
      "           Conv2d-15          [-1, 256, 60, 60]         295,168\n",
      "      BatchNorm2d-16          [-1, 256, 60, 60]             512\n",
      "             ReLU-17          [-1, 256, 60, 60]               0\n",
      "           Conv2d-18          [-1, 256, 60, 60]         590,080\n",
      "      BatchNorm2d-19          [-1, 256, 60, 60]             512\n",
      "             ReLU-20          [-1, 256, 60, 60]               0\n",
      "           Conv2d-21          [-1, 256, 60, 60]         590,080\n",
      "      BatchNorm2d-22          [-1, 256, 60, 60]             512\n",
      "             ReLU-23          [-1, 256, 60, 60]               0\n",
      "        MaxPool2d-24          [-1, 256, 30, 30]               0\n",
      "           Conv2d-25          [-1, 512, 30, 30]       1,180,160\n",
      "      BatchNorm2d-26          [-1, 512, 30, 30]           1,024\n",
      "             ReLU-27          [-1, 512, 30, 30]               0\n",
      "           Conv2d-28          [-1, 512, 30, 30]       2,359,808\n",
      "      BatchNorm2d-29          [-1, 512, 30, 30]           1,024\n",
      "             ReLU-30          [-1, 512, 30, 30]               0\n",
      "           Conv2d-31          [-1, 512, 30, 30]       2,359,808\n",
      "      BatchNorm2d-32          [-1, 512, 30, 30]           1,024\n",
      "             ReLU-33          [-1, 512, 30, 30]               0\n",
      "        MaxPool2d-34          [-1, 512, 15, 15]               0\n",
      "           Conv2d-35          [-1, 512, 15, 15]       2,359,808\n",
      "      BatchNorm2d-36          [-1, 512, 15, 15]           1,024\n",
      "             ReLU-37          [-1, 512, 15, 15]               0\n",
      "           Conv2d-38          [-1, 512, 15, 15]       2,359,808\n",
      "      BatchNorm2d-39          [-1, 512, 15, 15]           1,024\n",
      "             ReLU-40          [-1, 512, 15, 15]               0\n",
      "           Conv2d-41          [-1, 512, 15, 15]       2,359,808\n",
      "      BatchNorm2d-42          [-1, 512, 15, 15]           1,024\n",
      "             ReLU-43          [-1, 512, 15, 15]               0\n",
      "        MaxPool2d-44            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-45            [-1, 512, 7, 7]               0\n",
      "           Linear-46                    [-1, 1]          25,089\n",
      "================================================================\n",
      "Total params: 14,748,225\n",
      "Trainable params: 14,748,225\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.66\n",
      "Forward/backward pass size (MB): 369.52\n",
      "Params size (MB): 56.26\n",
      "Estimated Total Size (MB): 426.44\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 795/795 [03:40<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Confusion Matrix:\n",
      "[[    0     0]\n",
      " [76307     0]]\n",
      "Accuracy: 0.0000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "Min Probability: 1.0000\n",
      "Max Probability: 1.0000\n",
      "Standard Deviation of Probabilities: 0.0000\n",
      "Mean Probability: 1.0000\n",
      "CPU times: user 4min 13s, sys: 26.9 s, total: 4min 40s\n",
      "Wall time: 4min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ModelTester at 0x7f24846a8c70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "dataset = ImageDataset(labeled_image_paths=[item for item in labeled_image_paths if item[1] == 1],\n",
    "                       transform=transform)\n",
    "\n",
    "data_loader = DataLoaderMaker(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers)\n",
    "\n",
    "PreModelTester(path=path, device=device, dataloader=data_loader.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
